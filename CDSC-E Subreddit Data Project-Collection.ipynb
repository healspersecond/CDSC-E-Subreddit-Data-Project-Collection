{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Subreddit level data collection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each code chunk will execute one step in the process of collecting subreddit level data, including information on its moderators and the rules inputed into its Automoderator. Part 1 will first get us a full list of subreddit names starting from the most recent subreddit created all the way back to /r/reddit.com, which should always be at the end of the list. In Part 2, we will then iterate over this list to crawl each subreddit's /r/(subreddit)/about.json, r/(subreddit)/about/moderators.json, and r/(subreddit)/about/rules.json. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Get list of all <span style=\"color:red\"> subreddit names</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: change the custom user agent and script variables to your liking.        \n",
    "\n",
    "Also, change the `times_run` variable to a number like `30,000`. This should sufficiently get the scraper to go back 30,000 pages in time in subreddit names. It will not actually do 30,000 web crawls---the code will stop probably around 20,000, as the number of subreddits is close to 2,000,000 (each page will contain 100 subreddits, so 30,000 * 100 = 3 million as a safe upperbound)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "subreddit_list-02-11-2020.tsv\n",
      "{'User-Agent': 'healspersecond_ckiene_uw-com/subreddit_list_creator/1 CPython/3.7.4 Windows/10'}\n",
      "Request  1  completed! after_token:  t5_3cgm97\n",
      "Request  2  completed! after_token:  t5_3cg7uh\n",
      "Request  3  completed! after_token:  t5_3cfu1r\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import csv\n",
    "import time\n",
    "from datetime import datetime\n",
    "from datetime import timedelta\n",
    "from requests_toolbelt import user_agent\n",
    "from requests import Session\n",
    "import re\n",
    "from pprint import pprint\n",
    "import pandas as pd\n",
    "\n",
    "# Prepare output file with date of scrape\n",
    "today = datetime.today()\n",
    "output_file = \"subreddit_list-\" + today.strftime(\"%d-%m-%Y\") + \".tsv\"\n",
    "print(output_file)\n",
    "\n",
    "# Enter your custom script and user agent information\n",
    "user_agent_name = \"healspersecond_ckiene_uw-com\"\n",
    "script_name = \"subreddit_list_creator\"\n",
    "script_vers = \"1\"\n",
    "my_script = \"{}/{}\".format(script_name, script_vers)\n",
    "\n",
    "s = Session()\n",
    "s.headers = { \n",
    "    'User-Agent': user_agent(user_agent_name, my_script)\n",
    "    }\n",
    "print(s.headers)\n",
    "\n",
    "# Define functions to parse json \n",
    "header = ['display_name']\n",
    "\n",
    "def parse_response(User):\n",
    "    pprint(display_name())\n",
    "    return data\n",
    "\n",
    "def display_name():\n",
    "    result = data['data']['children'][n]['data']['display_name']\n",
    "    return result\n",
    "\n",
    "results = [] \n",
    "dict = {}\n",
    "\n",
    "# The URL to directly crawl the API---feel free to change it to your desired API endpoint\n",
    "request_url = 'https://www.reddit.com/subreddits/new.json?limit=100'\n",
    "r = requests.get(request_url, headers= s.headers)\n",
    "data = r.json()\n",
    "after_token = data['data']['after']\n",
    "\n",
    "sub_number = len(data['data']['children'])\n",
    "sub_num_seq = list(range(0,sub_number))\n",
    "\n",
    "for item in header:\n",
    "    for n in sub_num_seq :\n",
    "        dict[item] = data['data']['children'][n]['data'][item]\n",
    "        results.append(dict)#[item])\n",
    "\n",
    "# Specify number of pages to crawl back\n",
    "times_run =  3\n",
    "\n",
    "# Note: 30,000 will crawl back far enough to capture all subreddits and is suggested\n",
    "\n",
    "with open(output_file, 'w') as csvfile:\n",
    "    fieldnames = results[0].keys()\n",
    "    writer = csv.DictWriter(csvfile, fieldnames=fieldnames, delimiter='\\t')\n",
    "    writer.writeheader()\n",
    "\n",
    "    i = 1\n",
    "    while i <= times_run:\n",
    "        if after_token == None:\n",
    "            print(\"End of list at: \",i-1)\n",
    "            break\n",
    "        else:\n",
    "            request_url = 'https://www.reddit.com/subreddits/new.json?limit=100&after='+after_token\n",
    "            response = requests.get(request_url)\n",
    "            if response.status_code != 200: \n",
    "                continue\n",
    "            else:\n",
    "                r = requests.get(request_url, headers= s.headers)\n",
    "                data = r.json()\n",
    "                sub_number = len(data['data']['children'])\n",
    "                sub_num_seq = list(range(0,sub_number))\n",
    "                after_token = data['data']['after']\n",
    "                   \n",
    "                for item in header:\n",
    "                    for n in sub_num_seq:\n",
    "                        dict[item] = data['data']['children'][n]['data'][item]\n",
    "                        results.append(dict[item])\n",
    "                        writer.writerow(dict)  #add to list\n",
    "                print(\"Request \", i, \" completed! after_token: \", after_token) \n",
    "                i = i + 1\n",
    "\n",
    "# If things break, the last after_token can be used in the request_url to pick up where you left off"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>display_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>DidEDigUniPD20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>BuildsofSkyrim</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>lexmeme</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>suchblank</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Desolate_Era</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>295</td>\n",
       "      <td>GenshinTheoryCraft</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>296</td>\n",
       "      <td>MemeinVietnam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>297</td>\n",
       "      <td>DarkMayhem65t</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>298</td>\n",
       "      <td>HOABattles</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>299</td>\n",
       "      <td>1920Hoi4mod</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>300 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           display_name\n",
       "0        DidEDigUniPD20\n",
       "1        BuildsofSkyrim\n",
       "2               lexmeme\n",
       "3             suchblank\n",
       "4          Desolate_Era\n",
       "..                  ...\n",
       "295  GenshinTheoryCraft\n",
       "296       MemeinVietnam\n",
       "297       DarkMayhem65t\n",
       "298          HOABattles\n",
       "299         1920Hoi4mod\n",
       "\n",
       "[300 rows x 1 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_table(output_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Crawl reddit URLs and store <span style=\"color:red\">JSON</span> for each subreddit to <span style=\"color:red\">SQLite3 db</span> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 / 300 DidEDigUniPD20\n",
      "299 subreddits remaining.\n",
      "0:08:53.575303 time remaining.\n",
      "2 / 300 BuildsofSkyrim\n",
      "298 subreddits remaining.\n",
      "0:07:25.296393 time remaining.\n",
      "3 / 300 lexmeme\n",
      "297 subreddits remaining.\n",
      "0:07:04.728265 time remaining.\n",
      "4 / 300 suchblank\n",
      "296 subreddits remaining.\n",
      "0:06:48.460785 time remaining.\n",
      "5 / 300 Desolate_Era\n",
      "295 subreddits remaining.\n",
      "0:06:48.040449 time remaining.\n",
      "6 / 300 SumnerMemorialHS\n",
      "294 subreddits remaining.\n",
      "0:07:06.102451 time remaining.\n",
      "7 / 300 Throwbackk\n",
      "293 subreddits remaining.\n",
      "0:06:53.527020 time remaining.\n",
      "8 / 300 surprise_crochet\n",
      "292 subreddits remaining.\n",
      "0:06:45.023361 time remaining.\n",
      "9 / 300 Blacklyte\n",
      "291 subreddits remaining.\n",
      "0:06:37.718253 time remaining.\n",
      "10 / 300 cryptonix\n",
      "290 subreddits remaining.\n",
      "0:06:40.950356 time remaining.\n",
      "11 / 300 UsefulBookshop101\n",
      "289 subreddits remaining.\n",
      "0:06:34.968714 time remaining.\n",
      "12 / 300 NickiOsak\n",
      "288 subreddits remaining.\n",
      "0:06:54.223755 time remaining.\n",
      "13 / 300 WokeJusticeWarriorz\n",
      "287 subreddits remaining.\n",
      "0:06:53.292765 time remaining.\n",
      "14 / 300 ChadFredrickWolf\n",
      "286 subreddits remaining.\n",
      "0:08:36.070591 time remaining.\n",
      "15 / 300 sprotsrlivest\n",
      "285 subreddits remaining.\n",
      "0:08:23.866247 time remaining.\n",
      "16 / 300 UTCringe\n",
      "284 subreddits remaining.\n",
      "0:08:17.320628 time remaining.\n",
      "17 / 300 gaming4ever\n",
      "283 subreddits remaining.\n",
      "0:08:07.711576 time remaining.\n",
      "18 / 300 terroer\n",
      "282 subreddits remaining.\n",
      "0:08:15.578462 time remaining.\n",
      "19 / 300 SeanAndKaycee\n",
      "281 subreddits remaining.\n",
      "0:08:25.287438 time remaining.\n",
      "20 / 300 ParanormalPortal\n",
      "280 subreddits remaining.\n",
      "0:08:22.394486 time remaining.\n",
      "21 / 300 blancmasks\n",
      "279 subreddits remaining.\n",
      "0:08:12.532517 time remaining.\n",
      "22 / 300 catsarecereal\n",
      "278 subreddits remaining.\n",
      "0:08:08.922773 time remaining.\n",
      "23 / 300 GeneralMeems\n",
      "277 subreddits remaining.\n",
      "0:08:01.604787 time remaining.\n",
      "24 / 300 tropicxo\n",
      "276 subreddits remaining.\n",
      "0:07:53.965570 time remaining.\n",
      "25 / 300 CrypticMysteries\n",
      "275 subreddits remaining.\n",
      "0:07:48.865191 time remaining.\n",
      "26 / 300 sealab_2012\n",
      "274 subreddits remaining.\n",
      "0:07:45.019080 time remaining.\n",
      "27 / 300 FluffyTest2\n",
      "273 subreddits remaining.\n",
      "0:07:41.640093 time remaining.\n",
      "28 / 300 nuclear_power\n",
      "272 subreddits remaining.\n",
      "0:07:35.544394 time remaining.\n",
      "29 / 300 Misfitmaniac\n",
      "271 subreddits remaining.\n",
      "0:07:36.667437 time remaining.\n",
      "30 / 300 SnowPeaCockVore\n",
      "270 subreddits remaining.\n",
      "0:07:31.310113 time remaining.\n",
      "31 / 300 FindingTheBetterWay\n",
      "269 subreddits remaining.\n",
      "0:07:27.709826 time remaining.\n",
      "32 / 300 nuclear_questions\n",
      "268 subreddits remaining.\n",
      "0:07:22.814817 time remaining.\n",
      "33 / 300 onlykuyas\n",
      "267 subreddits remaining.\n",
      "0:07:26.050592 time remaining.\n",
      "34 / 300 AnixRBLX_Fan_Club\n",
      "266 subreddits remaining.\n",
      "0:07:21.050829 time remaining.\n",
      "35 / 300 Animalcrossingvillage\n",
      "265 subreddits remaining.\n",
      "0:07:17.455356 time remaining.\n",
      "36 / 300 SamuelPoorman\n",
      "264 subreddits remaining.\n",
      "0:07:14.473484 time remaining.\n",
      "37 / 300 DjamiahTemptation\n",
      "263 subreddits remaining.\n",
      "0:07:20.199363 time remaining.\n",
      "38 / 300 vorsen\n",
      "262 subreddits remaining.\n",
      "0:07:16.936214 time remaining.\n",
      "39 / 300 DialUpCats\n",
      "261 subreddits remaining.\n",
      "0:07:12.209090 time remaining.\n",
      "40 / 300 JasperRobloxx\n",
      "260 subreddits remaining.\n",
      "0:07:09.342744 time remaining.\n",
      "41 / 300 lamzakpodcast\n",
      "259 subreddits remaining.\n",
      "0:07:06.067176 time remaining.\n",
      "42 / 300 councilofmeat\n",
      "258 subreddits remaining.\n",
      "0:07:08.405297 time remaining.\n",
      "43 / 300 bettermtd\n",
      "257 subreddits remaining.\n",
      "0:07:07.611827 time remaining.\n",
      "44 / 300 JynxonicRule34\n",
      "256 subreddits remaining.\n",
      "0:07:03.287180 time remaining.\n",
      "45 / 300 indianmotomods\n",
      "255 subreddits remaining.\n",
      "0:07:04.869068 time remaining.\n",
      "46 / 300 Line3MN\n",
      "254 subreddits remaining.\n",
      "0:07:00.609765 time remaining.\n",
      "47 / 300 Animalcrossvillagers\n",
      "253 subreddits remaining.\n",
      "0:06:58.393394 time remaining.\n",
      "48 / 300 BoneworksVideos\n",
      "252 subreddits remaining.\n",
      "0:06:55.109145 time remaining.\n",
      "49 / 300 AverageRuqquser\n",
      "251 subreddits remaining.\n",
      "0:06:56.000480 time remaining.\n",
      "50 / 300 SlimeBreaker\n",
      "250 subreddits remaining.\n",
      "0:06:52.131464 time remaining.\n",
      "51 / 300 TheMoistboys\n",
      "249 subreddits remaining.\n",
      "0:06:50.697407 time remaining.\n",
      "52 / 300 GamerHorde\n",
      "248 subreddits remaining.\n",
      "0:06:46.866749 time remaining.\n",
      "53 / 300 Zaolzie\n",
      "247 subreddits remaining.\n",
      "0:06:46.151187 time remaining.\n",
      "54 / 300 Horny_Report\n",
      "246 subreddits remaining.\n",
      "0:06:42.945574 time remaining.\n",
      "55 / 300 lamza\n",
      "245 subreddits remaining.\n",
      "0:06:39.532778 time remaining.\n",
      "56 / 300 redditisracistfrl\n",
      "244 subreddits remaining.\n",
      "0:06:38.925336 time remaining.\n",
      "57 / 300 ValorantPhilippines\n",
      "243 subreddits remaining.\n",
      "0:06:36.605418 time remaining.\n",
      "58 / 300 Conspirasillies\n",
      "242 subreddits remaining.\n",
      "0:06:33.320773 time remaining.\n",
      "59 / 300 okbunnysenpai\n",
      "241 subreddits remaining.\n",
      "0:06:31.313651 time remaining.\n",
      "60 / 300 CPTSDMonsters\n",
      "240 subreddits remaining.\n",
      "0:06:28.457631 time remaining.\n",
      "61 / 300 Minecraftbattlebuilds\n",
      "239 subreddits remaining.\n",
      "0:06:29.179414 time remaining.\n",
      "62 / 300 Horny_F\n",
      "238 subreddits remaining.\n",
      "0:06:26.129630 time remaining.\n",
      "63 / 300 httydgames\n",
      "237 subreddits remaining.\n",
      "0:06:24.866809 time remaining.\n",
      "64 / 300 formyselftt\n",
      "236 subreddits remaining.\n",
      "0:06:21.884672 time remaining.\n",
      "65 / 300 ThisIsStockerHD\n",
      "235 subreddits remaining.\n",
      "0:06:22.118223 time remaining.\n",
      "66 / 300 MemeswithOddities\n",
      "234 subreddits remaining.\n",
      "0:06:19.326014 time remaining.\n",
      "67 / 300 10thgens\n",
      "233 subreddits remaining.\n",
      "0:06:17.098786 time remaining.\n",
      "68 / 300 womaen\n",
      "232 subreddits remaining.\n",
      "0:06:18.896537 time remaining.\n",
      "69 / 300 Allthingsanyeverywher\n",
      "231 subreddits remaining.\n",
      "0:06:15.823323 time remaining.\n",
      "70 / 300 thingsgingiknows\n",
      "230 subreddits remaining.\n",
      "0:06:12.785456 time remaining.\n",
      "71 / 300 FNCringey\n",
      "229 subreddits remaining.\n",
      "0:06:10.614532 time remaining.\n",
      "72 / 300 huxlow\n",
      "228 subreddits remaining.\n",
      "0:06:07.690296 time remaining.\n",
      "73 / 300 Paralor\n",
      "227 subreddits remaining.\n",
      "0:06:08.667668 time remaining.\n",
      "74 / 300 fulwuuss\n",
      "226 subreddits remaining.\n",
      "0:06:05.774473 time remaining.\n",
      "75 / 300 Vibeee\n",
      "225 subreddits remaining.\n",
      "0:06:02.951725 time remaining.\n",
      "76 / 300 The_Bananabois\n",
      "224 subreddits remaining.\n",
      "0:06:01.072426 time remaining.\n",
      "77 / 300 acsas\n",
      "223 subreddits remaining.\n",
      "0:05:59.403839 time remaining.\n",
      "78 / 300 AOOKO\n",
      "222 subreddits remaining.\n",
      "0:05:57.383981 time remaining.\n",
      "79 / 300 the_skeletons_lair\n",
      "221 subreddits remaining.\n",
      "0:05:54.603922 time remaining.\n",
      "80 / 300 MusicAML\n",
      "220 subreddits remaining.\n",
      "0:05:54.622822 time remaining.\n",
      "81 / 300 TXDPSRP\n",
      "219 subreddits remaining.\n",
      "0:05:51.971682 time remaining.\n",
      "82 / 300 Verbiage\n",
      "218 subreddits remaining.\n",
      "0:05:49.957943 time remaining.\n",
      "83 / 300 theydeservearaise\n",
      "217 subreddits remaining.\n",
      "0:05:50.444862 time remaining.\n",
      "84 / 300 ButDoesThisOne\n",
      "216 subreddits remaining.\n",
      "0:05:47.685756 time remaining.\n",
      "85 / 300 Scavineer\n",
      "215 subreddits remaining.\n",
      "0:05:45.729845 time remaining.\n",
      "86 / 300 okbuddytechtips\n",
      "214 subreddits remaining.\n",
      "0:05:43.726643 time remaining.\n",
      "87 / 300 nameaworstcombo\n",
      "213 subreddits remaining.\n",
      "0:05:41.225272 time remaining.\n",
      "88 / 300 WhatIShouldHaveDone2\n",
      "212 subreddits remaining.\n",
      "0:05:41.216762 time remaining.\n",
      "89 / 300 MaxTheDunce\n",
      "211 subreddits remaining.\n",
      "0:05:39.240338 time remaining.\n",
      "90 / 300 MAID4mentalillness\n",
      "210 subreddits remaining.\n",
      "0:05:39.059705 time remaining.\n",
      "91 / 300 TBOL\n",
      "209 subreddits remaining.\n",
      "0:05:37.076925 time remaining.\n",
      "92 / 300 RealAntiHornyAlliance\n",
      "208 subreddits remaining.\n",
      "0:05:34.926872 time remaining.\n",
      "93 / 300 HBO_euphoria\n",
      "207 subreddits remaining.\n",
      "0:05:32.429252 time remaining.\n",
      "94 / 300 Ijustwanttobeamod2\n",
      "206 subreddits remaining.\n",
      "0:05:29.972155 time remaining.\n",
      "95 / 300 FiskerMotors\n",
      "205 subreddits remaining.\n",
      "0:05:28.387776 time remaining.\n",
      "96 / 300 Bannonewnormal\n",
      "204 subreddits remaining.\n",
      "0:05:25.900027 time remaining.\n",
      "97 / 300 onlimits\n",
      "203 subreddits remaining.\n",
      "0:05:25.721187 time remaining.\n",
      "98 / 300 Shoffly\n",
      "202 subreddits remaining.\n",
      "0:05:23.315877 time remaining.\n",
      "99 / 300 IsraeliSupport\n",
      "201 subreddits remaining.\n",
      "0:05:20.904112 time remaining.\n",
      "100 / 300 CarWashProblems\n",
      "200 subreddits remaining.\n",
      "0:05:18.664688 time remaining.\n",
      "101 / 300 Abdlst\n",
      "199 subreddits remaining.\n",
      "0:05:16.418725 time remaining.\n",
      "102 / 300 CALLOFDUTYMGAMELOOP\n",
      "198 subreddits remaining.\n",
      "0:05:16.156270 time remaining.\n",
      "103 / 300 imsammerandthisisdeep\n",
      "197 subreddits remaining.\n",
      "0:05:13.790221 time remaining.\n",
      "104 / 300 KidsforKars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "196 subreddits remaining.\n",
      "0:05:11.443872 time remaining.\n",
      "105 / 300 weebsANDgamers\n",
      "195 subreddits remaining.\n",
      "0:05:10.214288 time remaining.\n",
      "106 / 300 eatshitapple\n",
      "194 subreddits remaining.\n",
      "0:05:07.912766 time remaining.\n",
      "107 / 300 AskMonkeys\n",
      "193 subreddits remaining.\n",
      "0:05:05.639006 time remaining.\n",
      "108 / 300 OhSoYouLike\n",
      "192 subreddits remaining.\n",
      "0:05:03.346754 time remaining.\n",
      "109 / 300 TeenageRants\n",
      "191 subreddits remaining.\n",
      "0:05:01.377350 time remaining.\n",
      "110 / 300 BloodyEvil\n",
      "190 subreddits remaining.\n",
      "0:05:02.935361 time remaining.\n",
      "111 / 300 MCBloodAndSteel\n",
      "189 subreddits remaining.\n",
      "0:05:02.584959 time remaining.\n",
      "112 / 300 RogerWakefieldPosts\n",
      "188 subreddits remaining.\n",
      "0:05:00.377321 time remaining.\n",
      "113 / 300 randomnessandlaughs\n",
      "187 subreddits remaining.\n",
      "0:04:58.108972 time remaining.\n",
      "114 / 300 advertise_anything\n",
      "186 subreddits remaining.\n",
      "0:04:55.853781 time remaining.\n",
      "115 / 300 AM2Kofficial\n",
      "185 subreddits remaining.\n",
      "0:04:53.722593 time remaining.\n",
      "116 / 300 FuckCrossplay\n",
      "184 subreddits remaining.\n",
      "0:04:51.521583 time remaining.\n",
      "117 / 300 MarkusMiiverse\n",
      "183 subreddits remaining.\n",
      "0:04:49.798692 time remaining.\n",
      "118 / 300 BernieCanStillWinguys\n",
      "182 subreddits remaining.\n",
      "0:04:47.618083 time remaining.\n",
      "119 / 300 MomsAreGreat\n",
      "181 subreddits remaining.\n",
      "0:04:45.492832 time remaining.\n",
      "120 / 300 dombox\n",
      "180 subreddits remaining.\n",
      "0:04:43.411911 time remaining.\n",
      "121 / 300 JujutsuKaisenMemes\n",
      "179 subreddits remaining.\n",
      "0:04:41.290821 time remaining.\n",
      "122 / 300 ExcludedUK\n",
      "178 subreddits remaining.\n",
      "0:04:39.181097 time remaining.\n",
      "123 / 300 Drugsarebadmkayyy\n",
      "177 subreddits remaining.\n",
      "0:04:37.122851 time remaining.\n",
      "124 / 300 DingowithFries\n",
      "176 subreddits remaining.\n",
      "0:04:35.389102 time remaining.\n",
      "125 / 300 MemesFreeXD\n",
      "175 subreddits remaining.\n",
      "0:04:33.310336 time remaining.\n",
      "126 / 300 fordcmax\n",
      "174 subreddits remaining.\n",
      "0:04:31.580035 time remaining.\n",
      "127 / 300 alfieindra\n",
      "173 subreddits remaining.\n",
      "0:04:29.516193 time remaining.\n",
      "128 / 300 BasedDeparrment\n",
      "172 subreddits remaining.\n",
      "0:04:27.555418 time remaining.\n",
      "129 / 300 footsandwich\n",
      "171 subreddits remaining.\n",
      "0:04:26.483826 time remaining.\n",
      "130 / 300 psychoticbutlegal\n",
      "170 subreddits remaining.\n",
      "0:04:25.835008 time remaining.\n",
      "131 / 300 FortniteUwU\n",
      "169 subreddits remaining.\n",
      "0:04:23.859523 time remaining.\n",
      "132 / 300 ClassicFundamentalism\n",
      "168 subreddits remaining.\n",
      "0:04:21.832695 time remaining.\n",
      "133 / 300 WeirdMovieScreenshot\n",
      "167 subreddits remaining.\n",
      "0:04:19.834707 time remaining.\n",
      "134 / 300 ThePolarity\n",
      "166 subreddits remaining.\n",
      "0:04:18.095235 time remaining.\n",
      "135 / 300 Tulipomania\n",
      "165 subreddits remaining.\n",
      "0:04:16.213885 time remaining.\n",
      "136 / 300 buccaneersvsgiantshq\n",
      "164 subreddits remaining.\n",
      "0:04:14.643600 time remaining.\n",
      "137 / 300 CompetitiveWildRift\n",
      "163 subreddits remaining.\n",
      "0:04:14.576577 time remaining.\n",
      "138 / 300 Cringegameplays\n",
      "162 subreddits remaining.\n",
      "0:04:13.637491 time remaining.\n",
      "139 / 300 2020ElectionNews\n",
      "161 subreddits remaining.\n",
      "0:04:12.073197 time remaining.\n",
      "140 / 300 Aspirationsanddreams\n",
      "160 subreddits remaining.\n",
      "0:04:11.250647 time remaining.\n",
      "141 / 300 smartyoungpeople\n",
      "159 subreddits remaining.\n",
      "0:04:10.397045 time remaining.\n",
      "142 / 300 TurksLand\n",
      "158 subreddits remaining.\n",
      "0:04:08.381811 time remaining.\n",
      "143 / 300 Unsoliciteddikdikpics\n",
      "157 subreddits remaining.\n",
      "0:04:07.512831 time remaining.\n",
      "144 / 300 disgustedangryupvote\n",
      "156 subreddits remaining.\n",
      "0:04:05.507857 time remaining.\n",
      "145 / 300 rugbyespana\n",
      "155 subreddits remaining.\n",
      "0:04:03.524412 time remaining.\n",
      "146 / 300 Schwiizer\n",
      "154 subreddits remaining.\n",
      "0:04:03.799945 time remaining.\n",
      "147 / 300 adishankarabot\n",
      "153 subreddits remaining.\n",
      "0:04:02.211352 time remaining.\n",
      "148 / 300 Education_Marketing\n",
      "152 subreddits remaining.\n",
      "0:04:00.231271 time remaining.\n",
      "149 / 300 ILoveDrywall\n",
      "151 subreddits remaining.\n",
      "0:03:58.943313 time remaining.\n",
      "150 / 300 buccaneersvsgiantshd\n",
      "150 subreddits remaining.\n",
      "0:03:57.306814 time remaining.\n",
      "151 / 300 2SouthAmerica4you\n",
      "149 subreddits remaining.\n",
      "0:03:56.038148 time remaining.\n",
      "152 / 300 FORBIDDENSKYPEOPLE\n",
      "148 subreddits remaining.\n",
      "0:03:54.078040 time remaining.\n",
      "153 / 300 BrokenBrawlStars\n",
      "147 subreddits remaining.\n",
      "0:03:52.126453 time remaining.\n",
      "154 / 300 DestroyDickDecemberr\n",
      "146 subreddits remaining.\n",
      "0:03:51.215140 time remaining.\n",
      "155 / 300 HochschuleMannheim\n",
      "145 subreddits remaining.\n",
      "0:03:49.280549 time remaining.\n",
      "156 / 300 risingtitanpersonal\n",
      "144 subreddits remaining.\n",
      "0:03:47.346951 time remaining.\n",
      "157 / 300 sonnydeluxe\n",
      "143 subreddits remaining.\n",
      "0:03:45.704393 time remaining.\n",
      "158 / 300 accidentalfarside\n",
      "142 subreddits remaining.\n",
      "0:03:43.779284 time remaining.\n",
      "159 / 300 ERPsoftware\n",
      "141 subreddits remaining.\n",
      "0:03:42.267227 time remaining.\n",
      "160 / 300 Nude4Everyone\n",
      "140 subreddits remaining.\n",
      "0:03:41.354675 time remaining.\n",
      "161 / 300 jokelore\n",
      "139 subreddits remaining.\n",
      "0:03:39.495550 time remaining.\n",
      "162 / 300 GetHornyJailed\n",
      "138 subreddits remaining.\n",
      "0:03:37.594383 time remaining.\n",
      "163 / 300 JustStatement\n",
      "137 subreddits remaining.\n",
      "0:03:36.366786 time remaining.\n",
      "164 / 300 superflatmc\n",
      "136 subreddits remaining.\n",
      "0:03:34.456749 time remaining.\n",
      "165 / 300 HikingMaine\n",
      "135 subreddits remaining.\n",
      "0:03:32.614515 time remaining.\n",
      "166 / 300 MarioMaker_fails\n",
      "134 subreddits remaining.\n",
      "0:03:30.768882 time remaining.\n",
      "167 / 300 RC_505\n",
      "133 subreddits remaining.\n",
      "0:03:28.943660 time remaining.\n",
      "168 / 300 slowkeyCollective\n",
      "132 subreddits remaining.\n",
      "0:03:27.387081 time remaining.\n",
      "169 / 300 LilExaine\n",
      "131 subreddits remaining.\n",
      "0:03:25.518625 time remaining.\n",
      "170 / 300 01_01_1\n",
      "130 subreddits remaining.\n",
      "0:03:23.944807 time remaining.\n",
      "171 / 300 specificaudience\n",
      "129 subreddits remaining.\n",
      "0:03:22.964204 time remaining.\n",
      "172 / 300 HimikoYumeno\n",
      "128 subreddits remaining.\n",
      "0:03:21.366993 time remaining.\n",
      "173 / 300 MetzlerBespoke\n",
      "127 subreddits remaining.\n",
      "0:03:19.560661 time remaining.\n",
      "174 / 300 IsItJanuary14th\n",
      "126 subreddits remaining.\n",
      "0:03:17.939675 time remaining.\n",
      "175 / 300 Councilofnut\n",
      "125 subreddits remaining.\n",
      "0:03:16.315393 time remaining.\n",
      "176 / 300 OGMadsnyds\n",
      "124 subreddits remaining.\n",
      "0:03:14.795165 time remaining.\n",
      "177 / 300 AntiHypeGaming\n",
      "123 subreddits remaining.\n",
      "0:03:13.280170 time remaining.\n",
      "178 / 300 DesertPirates\n",
      "122 subreddits remaining.\n",
      "0:03:11.528008 time remaining.\n",
      "179 / 300 R8MyGamingSetup\n",
      "121 subreddits remaining.\n",
      "0:03:09.756117 time remaining.\n",
      "180 / 300 ThatMonoOne\n",
      "120 subreddits remaining.\n",
      "0:03:07.962434 time remaining.\n",
      "181 / 300 ChungusOfTheBig\n",
      "119 subreddits remaining.\n",
      "0:03:06.392784 time remaining.\n",
      "182 / 300 RaidDislike\n",
      "118 subreddits remaining.\n",
      "0:03:04.822902 time remaining.\n",
      "183 / 300 SEADY\n",
      "117 subreddits remaining.\n",
      "0:03:03.236481 time remaining.\n",
      "184 / 300 THUGa\n",
      "116 subreddits remaining.\n",
      "0:03:01.762620 time remaining.\n",
      "185 / 300 RuralIowa\n",
      "115 subreddits remaining.\n",
      "0:02:59.958925 time remaining.\n",
      "186 / 300 creativefunserver\n",
      "114 subreddits remaining.\n",
      "0:02:58.231189 time remaining.\n",
      "187 / 300 ExpressYourselfFreely\n",
      "113 subreddits remaining.\n",
      "0:02:57.075942 time remaining.\n",
      "188 / 300 getghosted\n",
      "112 subreddits remaining.\n",
      "0:02:55.452732 time remaining.\n",
      "189 / 300 nexteducationlevel\n",
      "111 subreddits remaining.\n",
      "0:02:53.953084 time remaining.\n",
      "190 / 300 Manga_funny\n",
      "110 subreddits remaining.\n",
      "0:02:52.310438 time remaining.\n",
      "191 / 300 Clockworktestspace\n",
      "109 subreddits remaining.\n",
      "0:02:50.538864 time remaining.\n",
      "192 / 300 AzuralFanClub\n",
      "108 subreddits remaining.\n",
      "0:02:48.972186 time remaining.\n",
      "193 / 300 preipo\n",
      "107 subreddits remaining.\n",
      "0:02:47.193881 time remaining.\n",
      "194 / 300 UnrealExpectations\n",
      "106 subreddits remaining.\n",
      "0:02:45.439528 time remaining.\n",
      "195 / 300 XbowMasterrace\n",
      "105 subreddits remaining.\n",
      "0:02:43.972599 time remaining.\n",
      "196 / 300 PlantsWritingCorner\n",
      "104 subreddits remaining.\n",
      "0:02:42.341490 time remaining.\n",
      "197 / 300 nokarmawhoring\n",
      "103 subreddits remaining.\n",
      "0:02:40.745383 time remaining.\n",
      "198 / 300 wampgang\n",
      "102 subreddits remaining.\n",
      "0:02:38.988412 time remaining.\n",
      "199 / 300 GetTheNapalm\n",
      "101 subreddits remaining.\n",
      "0:02:37.375669 time remaining.\n",
      "200 / 300 CandidPorn\n",
      "100 subreddits remaining.\n",
      "0:02:35.763029 time remaining.\n",
      "201 / 300 BeautyGuruChatter2\n",
      "99 subreddits remaining.\n",
      "0:02:34.279198 time remaining.\n",
      "202 / 300 Planetking\n",
      "98 subreddits remaining.\n",
      "0:02:32.547943 time remaining.\n",
      "203 / 300 EuGravidaVendatur\n",
      "97 subreddits remaining.\n",
      "0:02:31.339361 time remaining.\n",
      "204 / 300 KadaisiNaal\n",
      "96 subreddits remaining.\n",
      "0:02:29.766275 time remaining.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "205 / 300 DoomViles\n",
      "95 subreddits remaining.\n",
      "0:02:28.029161 time remaining.\n",
      "206 / 300 processmanagement\n",
      "94 subreddits remaining.\n",
      "0:02:26.530165 time remaining.\n",
      "207 / 300 gsnee62\n",
      "93 subreddits remaining.\n",
      "0:02:25.336012 time remaining.\n",
      "208 / 300 AdviceaboutEHR\n",
      "92 subreddits remaining.\n",
      "0:02:23.606405 time remaining.\n",
      "209 / 300 TAWOTA\n",
      "91 subreddits remaining.\n",
      "0:02:21.873943 time remaining.\n",
      "210 / 300 TF2_hat_ideas\n",
      "90 subreddits remaining.\n",
      "0:02:20.148154 time remaining.\n",
      "211 / 300 WeldingMasters\n",
      "89 subreddits remaining.\n",
      "0:02:18.742988 time remaining.\n",
      "212 / 300 DronesUAV\n",
      "88 subreddits remaining.\n",
      "0:02:17.077693 time remaining.\n",
      "213 / 300 churchofgeg\n",
      "87 subreddits remaining.\n",
      "0:02:15.372062 time remaining.\n",
      "214 / 300 RickRollGang\n",
      "86 subreddits remaining.\n",
      "0:02:13.697744 time remaining.\n",
      "215 / 300 AndyGillion\n",
      "85 subreddits remaining.\n",
      "0:02:11.994423 time remaining.\n",
      "216 / 300 PeeCumMemez\n",
      "84 subreddits remaining.\n",
      "0:02:10.356875 time remaining.\n",
      "217 / 300 fromrussia\n",
      "83 subreddits remaining.\n",
      "0:02:08.782408 time remaining.\n",
      "218 / 300 justbymyself\n",
      "82 subreddits remaining.\n",
      "0:02:07.288878 time remaining.\n",
      "219 / 300 Vogelkult\n",
      "81 subreddits remaining.\n",
      "0:02:05.644226 time remaining.\n",
      "220 / 300 Foun\n",
      "80 subreddits remaining.\n",
      "0:02:04.008324 time remaining.\n",
      "221 / 300 TerrariaBossIdeas\n",
      "79 subreddits remaining.\n",
      "0:02:02.341131 time remaining.\n",
      "222 / 300 AboutPCsWiki\n",
      "78 subreddits remaining.\n",
      "0:02:00.672668 time remaining.\n",
      "223 / 300 Taco_Raccoon\n",
      "77 subreddits remaining.\n",
      "0:01:59.120137 time remaining.\n",
      "224 / 300 luxurycandles\n",
      "76 subreddits remaining.\n",
      "0:01:57.464310 time remaining.\n",
      "225 / 300 90sstyle\n",
      "75 subreddits remaining.\n",
      "0:01:55.800790 time remaining.\n",
      "226 / 300 FortniteMeme12\n",
      "74 subreddits remaining.\n",
      "0:01:54.387314 time remaining.\n",
      "227 / 300 SimpPoliceita\n",
      "73 subreddits remaining.\n",
      "0:01:52.752883 time remaining.\n",
      "228 / 300 convenientart\n",
      "72 subreddits remaining.\n",
      "0:01:51.563028 time remaining.\n",
      "229 / 300 naturefuckingshits\n",
      "71 subreddits remaining.\n",
      "0:01:49.972997 time remaining.\n",
      "230 / 300 DickRatingByJenna\n",
      "70 subreddits remaining.\n",
      "0:01:48.391463 time remaining.\n",
      "231 / 300 NewGamePlusTV\n",
      "69 subreddits remaining.\n",
      "0:01:46.741182 time remaining.\n",
      "232 / 300 SpeakerBuilding\n",
      "68 subreddits remaining.\n",
      "0:01:45.087238 time remaining.\n",
      "233 / 300 CheepToys\n",
      "67 subreddits remaining.\n",
      "0:01:43.728887 time remaining.\n",
      "234 / 300 nerfstryfe\n",
      "66 subreddits remaining.\n",
      "0:01:42.076567 time remaining.\n",
      "235 / 300 Gica_memes\n",
      "65 subreddits remaining.\n",
      "0:01:40.440317 time remaining.\n",
      "236 / 300 adworldconference\n",
      "64 subreddits remaining.\n",
      "0:01:38.815581 time remaining.\n",
      "237 / 300 Last2\n",
      "63 subreddits remaining.\n",
      "0:01:37.199310 time remaining.\n",
      "238 / 300 Forhonorfashion\n",
      "62 subreddits remaining.\n",
      "0:01:35.908582 time remaining.\n",
      "239 / 300 caughtshitting\n",
      "61 subreddits remaining.\n",
      "0:01:34.307493 time remaining.\n",
      "240 / 300 steeklo\n",
      "60 subreddits remaining.\n",
      "0:01:32.673719 time remaining.\n",
      "241 / 300 GTAO_Fans\n",
      "59 subreddits remaining.\n",
      "0:01:31.053264 time remaining.\n",
      "242 / 300 IndianCivics\n",
      "58 subreddits remaining.\n",
      "0:01:29.513119 time remaining.\n",
      "243 / 300 MwendwaMbaabu\n",
      "57 subreddits remaining.\n",
      "0:01:27.974249 time remaining.\n",
      "244 / 300 artizcommunity\n",
      "56 subreddits remaining.\n",
      "0:01:26.427147 time remaining.\n",
      "245 / 300 Roleplay1x1\n",
      "55 subreddits remaining.\n",
      "0:01:24.868748 time remaining.\n",
      "246 / 300 kristudio\n",
      "54 subreddits remaining.\n",
      "0:01:23.259826 time remaining.\n",
      "247 / 300 apexlegendsclubs\n",
      "53 subreddits remaining.\n",
      "0:01:21.641303 time remaining.\n",
      "248 / 300 lifestone\n",
      "52 subreddits remaining.\n",
      "0:01:20.030057 time remaining.\n",
      "249 / 300 Sealab2012_Resurgence\n",
      "51 subreddits remaining.\n",
      "0:01:18.541094 time remaining.\n",
      "250 / 300 haloweenassholes\n",
      "50 subreddits remaining.\n",
      "0:01:16.928071 time remaining.\n",
      "251 / 300 31sjsjsjsj\n",
      "49 subreddits remaining.\n",
      "0:01:15.323421 time remaining.\n",
      "252 / 300 treehut16\n",
      "48 subreddits remaining.\n",
      "0:01:13.785562 time remaining.\n",
      "253 / 300 VegasGayCouples\n",
      "47 subreddits remaining.\n",
      "0:01:12.242436 time remaining.\n",
      "254 / 300 specsforpc\n",
      "46 subreddits remaining.\n",
      "0:01:10.671059 time remaining.\n",
      "255 / 300 Indiangroundkeepers\n",
      "45 subreddits remaining.\n",
      "0:01:09.084569 time remaining.\n",
      "256 / 300 workalongs\n",
      "44 subreddits remaining.\n",
      "0:01:07.614916 time remaining.\n",
      "257 / 300 MysteriousShortStory\n",
      "43 subreddits remaining.\n",
      "0:01:06.019706 time remaining.\n",
      "258 / 300 ArcaneWarfareGame\n",
      "42 subreddits remaining.\n",
      "0:01:04.471570 time remaining.\n",
      "259 / 300 Gaming_stuff_\n",
      "41 subreddits remaining.\n",
      "0:01:02.932537 time remaining.\n",
      "260 / 300 tulopuedeshacer\n",
      "40 subreddits remaining.\n",
      "0:01:01.345071 time remaining.\n",
      "261 / 300 APKGamesGeeks\n",
      "39 subreddits remaining.\n",
      "0:00:59.760550 time remaining.\n",
      "262 / 300 Skeletonbenyo\n",
      "38 subreddits remaining.\n",
      "0:00:58.260744 time remaining.\n",
      "263 / 300 Animal_\n",
      "37 subreddits remaining.\n",
      "0:00:56.692666 time remaining.\n",
      "264 / 300 HoldMyCovid\n",
      "36 subreddits remaining.\n",
      "0:00:55.308798 time remaining.\n",
      "265 / 300 PortalToHistory\n",
      "35 subreddits remaining.\n",
      "0:00:53.763846 time remaining.\n",
      "266 / 300 Hitlarmemes69420\n",
      "34 subreddits remaining.\n",
      "0:00:52.181132 time remaining.\n",
      "267 / 300 SL0PEGAME\n",
      "33 subreddits remaining.\n",
      "0:00:50.602550 time remaining.\n",
      "268 / 300 60daysinuncensored\n",
      "32 subreddits remaining.\n",
      "0:00:49.033277 time remaining.\n",
      "269 / 300 ARandomSubredditHere\n",
      "31 subreddits remaining.\n",
      "0:00:47.474404 time remaining.\n",
      "270 / 300 sexydrummers\n",
      "30 subreddits remaining.\n",
      "0:00:45.918994 time remaining.\n",
      "271 / 300 JobSimulatorFans\n",
      "29 subreddits remaining.\n",
      "0:00:44.465708 time remaining.\n",
      "272 / 300 SmallYouTubePromo\n",
      "28 subreddits remaining.\n",
      "0:00:42.902737 time remaining.\n",
      "273 / 300 yolksthatendedtoosoon\n",
      "27 subreddits remaining.\n",
      "0:00:41.338828 time remaining.\n",
      "274 / 300 dirtyexxxchange\n",
      "26 subreddits remaining.\n",
      "0:00:39.773784 time remaining.\n",
      "275 / 300 oneblockaday\n",
      "25 subreddits remaining.\n",
      "0:00:38.236158 time remaining.\n",
      "276 / 300 Sentinus\n",
      "24 subreddits remaining.\n",
      "0:00:36.699998 time remaining.\n",
      "277 / 300 cultofmona\n",
      "23 subreddits remaining.\n",
      "0:00:35.147118 time remaining.\n",
      "278 / 300 SGFIFA\n",
      "22 subreddits remaining.\n",
      "0:00:33.593057 time remaining.\n",
      "279 / 300 drugsmarketplace\n",
      "21 subreddits remaining.\n",
      "0:00:32.040287 time remaining.\n",
      "280 / 300 Poolickpoo\n",
      "20 subreddits remaining.\n",
      "0:00:30.490258 time remaining.\n",
      "281 / 300 SavedArtPosts\n",
      "19 subreddits remaining.\n",
      "0:00:28.945768 time remaining.\n",
      "282 / 300 springvalleylore\n",
      "18 subreddits remaining.\n",
      "0:00:27.401311 time remaining.\n",
      "283 / 300 AvionenPapier\n",
      "17 subreddits remaining.\n",
      "0:00:25.859687 time remaining.\n",
      "284 / 300 MondayNightweek8\n",
      "16 subreddits remaining.\n",
      "0:00:24.322523 time remaining.\n",
      "285 / 300 StreamLocator\n",
      "15 subreddits remaining.\n",
      "0:00:22.822812 time remaining.\n",
      "286 / 300 addyourbusinesstome\n",
      "14 subreddits remaining.\n",
      "0:00:21.285407 time remaining.\n",
      "287 / 300 jeppis\n",
      "13 subreddits remaining.\n",
      "0:00:19.765176 time remaining.\n",
      "288 / 300 FlamingoOfficial\n",
      "12 subreddits remaining.\n",
      "0:00:18.240666 time remaining.\n",
      "289 / 300 War_in_Karabakh\n",
      "11 subreddits remaining.\n",
      "0:00:16.729153 time remaining.\n",
      "290 / 300 SerialGossipBiz\n",
      "10 subreddits remaining.\n",
      "0:00:15.206716 time remaining.\n",
      "291 / 300 Pitchgarden\n",
      "9 subreddits remaining.\n",
      "0:00:13.709171 time remaining.\n",
      "292 / 300 anielaleon2\n",
      "8 subreddits remaining.\n",
      "0:00:12.179296 time remaining.\n",
      "293 / 300 LearnLevantineArabic\n",
      "7 subreddits remaining.\n",
      "0:00:10.699013 time remaining.\n",
      "294 / 300 RoyalTutor\n",
      "6 subreddits remaining.\n",
      "0:00:09.166056 time remaining.\n",
      "295 / 300 ZonaMemes\n",
      "5 subreddits remaining.\n",
      "0:00:07.642030 time remaining.\n",
      "296 / 300 GenshinTheoryCraft\n",
      "4 subreddits remaining.\n",
      "0:00:06.109849 time remaining.\n",
      "297 / 300 MemeinVietnam\n",
      "3 subreddits remaining.\n",
      "0:00:04.581268 time remaining.\n",
      "298 / 300 DarkMayhem65t\n",
      "2 subreddits remaining.\n",
      "0:00:03.051920 time remaining.\n",
      "299 / 300 HOABattles\n",
      "1 subreddits remaining.\n",
      "0:00:01.525621 time remaining.\n",
      "300 / 300 1920Hoi4mod\n",
      "0 subreddits remaining.\n",
      "0:00:00 time remaining.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import sqlite3\n",
    "import csv\n",
    "import time\n",
    "import pandas as pd\n",
    "import re\n",
    "from requests import Session\n",
    "from requests_toolbelt import user_agent\n",
    "import datetime\n",
    "from datetime import timedelta\n",
    "import json\n",
    "\n",
    "conn = sqlite3.connect(\"test_db.db\")\n",
    "\n",
    "# List of subreddits to search\n",
    "sublist = pd.read_table(output_file, header = 0)\n",
    "sublist = sublist.display_name.tolist()\n",
    "\n",
    "# Time reporting variables\n",
    "i = 1\n",
    "start = time.time()\n",
    "list_len = len(sublist)\n",
    "\n",
    "       \n",
    "for sub in sublist:              \n",
    "    print(i, '/', list_len , sub)\n",
    "    \n",
    "    # JSON requests - subreddit info\n",
    "    dict_sub = {}\n",
    "    request_url_sub = 'https://www.reddit.com/r/'+sub+'/about.json'     \n",
    "    r_sub = requests.get(request_url_sub, headers = s.headers)\n",
    "    \n",
    "    try:\n",
    "        data_sub = r_sub.json()\n",
    "        sub_json_status = \"OK\"\n",
    "    except json.decoder.JSONDecodeError as err:\n",
    "        data_sub = str(err)\n",
    "        sub_json_status = str(err)\n",
    "    \n",
    "    # JSON requests - moderator info\n",
    "    dict_mod = {}\n",
    "    request_url_mod = 'https://www.reddit.com/r/'+sub+'/about/moderators.json'     \n",
    "    r_mod = requests.get(request_url_mod, headers = s.headers)\n",
    "\n",
    "    try:\n",
    "        data_mod = r_mod.json()\n",
    "        mod_json_status = \"OK\"\n",
    "    except json.decoder.JSONDecodeError as err:\n",
    "        data_mod = str(err)\n",
    "        mod_json_status = str(err)    \n",
    "\n",
    "    # JSON requests - rules info\n",
    "    dict_rules = {}\n",
    "    request_url_rules = 'https://www.reddit.com/r/'+sub+'/about/rules.json'     \n",
    "    r_rules = requests.get(request_url_rules, headers = s.headers)\n",
    "\n",
    "    try:\n",
    "        data_rules = r_rules.json()\n",
    "        rules_json_status = \"OK\"\n",
    "    except json.decoder.JSONDecodeError as err:\n",
    "        data_rules = str(err)\n",
    "        rules_json_status = str(err)\n",
    "        \n",
    "    timestamp = datetime.datetime.utcfromtimestamp(time.time()).strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "                \n",
    "    # Write to dictionary for subreddit table\n",
    "    dict_sub['subreddit'] = [sub]\n",
    "    dict_sub['sub_status'] = [r_sub.status_code]\n",
    "    dict_sub['headers'] = [str(r_sub.headers)]\n",
    "    dict_sub['sub_reason'] = [r_sub.reason]\n",
    "    dict_sub['sub_timestamp'] = [timestamp]\n",
    "    dict_sub['sub_json_status'] = [sub_json_status]\n",
    "    dict_sub['sub_json'] = [json.dumps(data_sub)]\n",
    "    \n",
    "    # Write to dictionary for mod table\n",
    "    dict_mod['subreddit'] = [sub]\n",
    "    dict_mod['mod_status'] = [r_mod.status_code]\n",
    "    dict_mod['headers'] = [str(r_mod.headers)]\n",
    "    dict_mod['mod_reason'] = [r_mod.reason]\n",
    "    dict_mod['mod_timestamp'] = [timestamp]\n",
    "    dict_mod['mod_json_status'] = [mod_json_status]\n",
    "    dict_mod['mod_json'] = [json.dumps(data_mod)]\n",
    "    \n",
    "    # Write to dictionary for rules table\n",
    "    dict_rules['subreddit'] = [sub]\n",
    "    dict_rules['rules_status'] = [r_rules.status_code]\n",
    "    dict_rules['headers'] = [str(r_rules.headers)]\n",
    "    dict_rules['rules_reason'] = [r_rules.reason]\n",
    "    dict_rules['rules_timestamp'] = [timestamp]\n",
    "    dict_rules['rules_json_status'] = [rules_json_status]\n",
    "    dict_rules['rules_json'] = [json.dumps(data_rules)]\n",
    "               \n",
    "    pd_sub = pd.DataFrame(dict_sub)\n",
    "    pd_sub.to_sql('sub_json', if_exists='append',con = conn, index=False)\n",
    "    \n",
    "    pd_mod = pd.DataFrame(dict_mod)\n",
    "    pd_mod.to_sql('mod_json', if_exists='append',con = conn, index=False)\n",
    "    \n",
    "    pd_rules = pd.DataFrame(dict_rules)\n",
    "    pd_rules.to_sql('rules_json', if_exists='append',con = conn, index=False)\n",
    "    \n",
    "    # Time reporting\n",
    "    finish = time.time()\n",
    "    list_len = len(sublist)\n",
    "    list_len_remain = list_len - i\n",
    "    seconds_per_sub = (finish - start) / i\n",
    "    seconds_remaining = list_len_remain * seconds_per_sub\n",
    "    print(list_len_remain, 'subreddits remaining.') \n",
    "    sec = timedelta(seconds=(seconds_remaining))\n",
    "    print(str(sec), \"time remaining.\")\n",
    "    time.sleep(0.5)\n",
    "    \n",
    "    i =  i + 1   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Examine the tables we've created:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subreddit</th>\n",
       "      <th>sub_status</th>\n",
       "      <th>headers</th>\n",
       "      <th>sub_reason</th>\n",
       "      <th>sub_timestamp</th>\n",
       "      <th>sub_json_status</th>\n",
       "      <th>sub_json</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>DidEDigUniPD20</td>\n",
       "      <td>200</td>\n",
       "      <td>{'Connection': 'keep-alive', 'Content-Length':...</td>\n",
       "      <td>OK</td>\n",
       "      <td>2020-11-02 18:06:54</td>\n",
       "      <td>OK</td>\n",
       "      <td>{\"kind\": \"t5\", \"data\": {\"user_flair_background...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>BuildsofSkyrim</td>\n",
       "      <td>200</td>\n",
       "      <td>{'Connection': 'keep-alive', 'Content-Length':...</td>\n",
       "      <td>OK</td>\n",
       "      <td>2020-11-02 18:06:55</td>\n",
       "      <td>OK</td>\n",
       "      <td>{\"kind\": \"t5\", \"data\": {\"user_flair_background...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>lexmeme</td>\n",
       "      <td>200</td>\n",
       "      <td>{'Connection': 'keep-alive', 'Content-Length':...</td>\n",
       "      <td>OK</td>\n",
       "      <td>2020-11-02 18:06:56</td>\n",
       "      <td>OK</td>\n",
       "      <td>{\"kind\": \"t5\", \"data\": {\"user_flair_background...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>suchblank</td>\n",
       "      <td>200</td>\n",
       "      <td>{'Connection': 'keep-alive', 'Content-Length':...</td>\n",
       "      <td>OK</td>\n",
       "      <td>2020-11-02 18:06:57</td>\n",
       "      <td>OK</td>\n",
       "      <td>{\"kind\": \"t5\", \"data\": {\"user_flair_background...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Desolate_Era</td>\n",
       "      <td>200</td>\n",
       "      <td>{'Connection': 'keep-alive', 'Content-Length':...</td>\n",
       "      <td>OK</td>\n",
       "      <td>2020-11-02 18:06:59</td>\n",
       "      <td>OK</td>\n",
       "      <td>{\"kind\": \"t5\", \"data\": {\"user_flair_background...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        subreddit  sub_status  \\\n",
       "0  DidEDigUniPD20         200   \n",
       "1  BuildsofSkyrim         200   \n",
       "2         lexmeme         200   \n",
       "3       suchblank         200   \n",
       "4    Desolate_Era         200   \n",
       "\n",
       "                                             headers sub_reason  \\\n",
       "0  {'Connection': 'keep-alive', 'Content-Length':...         OK   \n",
       "1  {'Connection': 'keep-alive', 'Content-Length':...         OK   \n",
       "2  {'Connection': 'keep-alive', 'Content-Length':...         OK   \n",
       "3  {'Connection': 'keep-alive', 'Content-Length':...         OK   \n",
       "4  {'Connection': 'keep-alive', 'Content-Length':...         OK   \n",
       "\n",
       "         sub_timestamp sub_json_status  \\\n",
       "0  2020-11-02 18:06:54              OK   \n",
       "1  2020-11-02 18:06:55              OK   \n",
       "2  2020-11-02 18:06:56              OK   \n",
       "3  2020-11-02 18:06:57              OK   \n",
       "4  2020-11-02 18:06:59              OK   \n",
       "\n",
       "                                            sub_json  \n",
       "0  {\"kind\": \"t5\", \"data\": {\"user_flair_background...  \n",
       "1  {\"kind\": \"t5\", \"data\": {\"user_flair_background...  \n",
       "2  {\"kind\": \"t5\", \"data\": {\"user_flair_background...  \n",
       "3  {\"kind\": \"t5\", \"data\": {\"user_flair_background...  \n",
       "4  {\"kind\": \"t5\", \"data\": {\"user_flair_background...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Subreddit's general information\n",
    "df_sub = pd.read_sql_query(\"select * from sub_json;\", conn)\n",
    "df_sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subreddit</th>\n",
       "      <th>mod_status</th>\n",
       "      <th>headers</th>\n",
       "      <th>mod_reason</th>\n",
       "      <th>mod_timestamp</th>\n",
       "      <th>mod_json_status</th>\n",
       "      <th>mod_json</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>DidEDigUniPD20</td>\n",
       "      <td>200</td>\n",
       "      <td>{'Connection': 'keep-alive', 'Content-Length':...</td>\n",
       "      <td>OK</td>\n",
       "      <td>2020-11-02 18:06:54</td>\n",
       "      <td>OK</td>\n",
       "      <td>{\"kind\": \"UserList\", \"data\": {\"children\": [{\"n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>BuildsofSkyrim</td>\n",
       "      <td>200</td>\n",
       "      <td>{'Connection': 'keep-alive', 'Content-Length':...</td>\n",
       "      <td>OK</td>\n",
       "      <td>2020-11-02 18:06:55</td>\n",
       "      <td>OK</td>\n",
       "      <td>{\"kind\": \"UserList\", \"data\": {\"children\": [{\"n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>lexmeme</td>\n",
       "      <td>200</td>\n",
       "      <td>{'Connection': 'keep-alive', 'Content-Length':...</td>\n",
       "      <td>OK</td>\n",
       "      <td>2020-11-02 18:06:56</td>\n",
       "      <td>OK</td>\n",
       "      <td>{\"kind\": \"UserList\", \"data\": {\"children\": [{\"n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>suchblank</td>\n",
       "      <td>200</td>\n",
       "      <td>{'Connection': 'keep-alive', 'Content-Length':...</td>\n",
       "      <td>OK</td>\n",
       "      <td>2020-11-02 18:06:57</td>\n",
       "      <td>OK</td>\n",
       "      <td>{\"kind\": \"UserList\", \"data\": {\"children\": [{\"n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Desolate_Era</td>\n",
       "      <td>200</td>\n",
       "      <td>{'Connection': 'keep-alive', 'Content-Length':...</td>\n",
       "      <td>OK</td>\n",
       "      <td>2020-11-02 18:06:59</td>\n",
       "      <td>OK</td>\n",
       "      <td>{\"kind\": \"UserList\", \"data\": {\"children\": [{\"n...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        subreddit  mod_status  \\\n",
       "0  DidEDigUniPD20         200   \n",
       "1  BuildsofSkyrim         200   \n",
       "2         lexmeme         200   \n",
       "3       suchblank         200   \n",
       "4    Desolate_Era         200   \n",
       "\n",
       "                                             headers mod_reason  \\\n",
       "0  {'Connection': 'keep-alive', 'Content-Length':...         OK   \n",
       "1  {'Connection': 'keep-alive', 'Content-Length':...         OK   \n",
       "2  {'Connection': 'keep-alive', 'Content-Length':...         OK   \n",
       "3  {'Connection': 'keep-alive', 'Content-Length':...         OK   \n",
       "4  {'Connection': 'keep-alive', 'Content-Length':...         OK   \n",
       "\n",
       "         mod_timestamp mod_json_status  \\\n",
       "0  2020-11-02 18:06:54              OK   \n",
       "1  2020-11-02 18:06:55              OK   \n",
       "2  2020-11-02 18:06:56              OK   \n",
       "3  2020-11-02 18:06:57              OK   \n",
       "4  2020-11-02 18:06:59              OK   \n",
       "\n",
       "                                            mod_json  \n",
       "0  {\"kind\": \"UserList\", \"data\": {\"children\": [{\"n...  \n",
       "1  {\"kind\": \"UserList\", \"data\": {\"children\": [{\"n...  \n",
       "2  {\"kind\": \"UserList\", \"data\": {\"children\": [{\"n...  \n",
       "3  {\"kind\": \"UserList\", \"data\": {\"children\": [{\"n...  \n",
       "4  {\"kind\": \"UserList\", \"data\": {\"children\": [{\"n...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Subreddit's moderator information\n",
    "df_mod = pd.read_sql_query(\"select * from mod_json;\", conn)\n",
    "df_mod.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subreddit</th>\n",
       "      <th>rules_status</th>\n",
       "      <th>headers</th>\n",
       "      <th>rules_reason</th>\n",
       "      <th>rules_timestamp</th>\n",
       "      <th>rules_json_status</th>\n",
       "      <th>rules_json</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>DidEDigUniPD20</td>\n",
       "      <td>200</td>\n",
       "      <td>{'Connection': 'keep-alive', 'Content-Length':...</td>\n",
       "      <td>OK</td>\n",
       "      <td>2020-11-02 18:06:54</td>\n",
       "      <td>OK</td>\n",
       "      <td>{\"rules\": [], \"site_rules\": [\"Spam\", \"Personal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>BuildsofSkyrim</td>\n",
       "      <td>200</td>\n",
       "      <td>{'Connection': 'keep-alive', 'Content-Length':...</td>\n",
       "      <td>OK</td>\n",
       "      <td>2020-11-02 18:06:55</td>\n",
       "      <td>OK</td>\n",
       "      <td>{\"rules\": [], \"site_rules\": [\"Spam\", \"Personal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>lexmeme</td>\n",
       "      <td>200</td>\n",
       "      <td>{'Connection': 'keep-alive', 'Content-Length':...</td>\n",
       "      <td>OK</td>\n",
       "      <td>2020-11-02 18:06:56</td>\n",
       "      <td>OK</td>\n",
       "      <td>{\"rules\": [], \"site_rules\": [\"Spam\", \"Personal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>suchblank</td>\n",
       "      <td>200</td>\n",
       "      <td>{'Connection': 'keep-alive', 'Content-Length':...</td>\n",
       "      <td>OK</td>\n",
       "      <td>2020-11-02 18:06:57</td>\n",
       "      <td>OK</td>\n",
       "      <td>{\"rules\": [], \"site_rules\": [\"Spam\", \"Personal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Desolate_Era</td>\n",
       "      <td>200</td>\n",
       "      <td>{'Connection': 'keep-alive', 'Content-Length':...</td>\n",
       "      <td>OK</td>\n",
       "      <td>2020-11-02 18:06:59</td>\n",
       "      <td>OK</td>\n",
       "      <td>{\"rules\": [], \"site_rules\": [\"Spam\", \"Personal...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        subreddit  rules_status  \\\n",
       "0  DidEDigUniPD20           200   \n",
       "1  BuildsofSkyrim           200   \n",
       "2         lexmeme           200   \n",
       "3       suchblank           200   \n",
       "4    Desolate_Era           200   \n",
       "\n",
       "                                             headers rules_reason  \\\n",
       "0  {'Connection': 'keep-alive', 'Content-Length':...           OK   \n",
       "1  {'Connection': 'keep-alive', 'Content-Length':...           OK   \n",
       "2  {'Connection': 'keep-alive', 'Content-Length':...           OK   \n",
       "3  {'Connection': 'keep-alive', 'Content-Length':...           OK   \n",
       "4  {'Connection': 'keep-alive', 'Content-Length':...           OK   \n",
       "\n",
       "       rules_timestamp rules_json_status  \\\n",
       "0  2020-11-02 18:06:54                OK   \n",
       "1  2020-11-02 18:06:55                OK   \n",
       "2  2020-11-02 18:06:56                OK   \n",
       "3  2020-11-02 18:06:57                OK   \n",
       "4  2020-11-02 18:06:59                OK   \n",
       "\n",
       "                                          rules_json  \n",
       "0  {\"rules\": [], \"site_rules\": [\"Spam\", \"Personal...  \n",
       "1  {\"rules\": [], \"site_rules\": [\"Spam\", \"Personal...  \n",
       "2  {\"rules\": [], \"site_rules\": [\"Spam\", \"Personal...  \n",
       "3  {\"rules\": [], \"site_rules\": [\"Spam\", \"Personal...  \n",
       "4  {\"rules\": [], \"site_rules\": [\"Spam\", \"Personal...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Subreddit's rules information\n",
    "df_rules  = pd.read_sql_query(\"select * from rules_json;\", conn)\n",
    "df_rules.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this code, we can generate a full and current list of subreddits and then used that list to collect the JSON on each of those subreddits. In the next section, I'll show you what this json data looks like when structured as a new dataframe using a new example of city related subreddits."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. JSON <span style=\"color:red\">data transformation</span> for each table's JSON column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, I'm going to add rows to our tables in our SQL db for some specific subreddits that I know will have populated JSON with moderator and rule information. Newer subreddits seem less likely to have this, so the ones we scraped in the code above would not be a great example to show what the final data set looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seattlewa\n",
      "nyc\n",
      "chicago\n",
      "losangeles\n",
      "atlanta\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import sqlite3\n",
    "import csv\n",
    "import time\n",
    "import pandas as pd\n",
    "import re\n",
    "from requests import Session\n",
    "from requests_toolbelt import user_agent\n",
    "import datetime\n",
    "from datetime import timedelta\n",
    "import json\n",
    "\n",
    "conn = sqlite3.connect(\"city_test.db\")\n",
    "\n",
    "city_subs = ('seattlewa', 'nyc', 'chicago', 'losangeles', 'atlanta')\n",
    "\n",
    "for sub in city_subs:                \n",
    "    # JSON requests - subreddit info\n",
    "    print(sub)\n",
    "    dict_sub = {}\n",
    "    request_url_sub = 'https://www.reddit.com/r/'+sub+'/about.json'     \n",
    "    r_sub = requests.get(request_url_sub, headers = s.headers)\n",
    "    \n",
    "    try:\n",
    "        data_sub = r_sub.json()\n",
    "        sub_json_status = \"OK\"\n",
    "    except json.decoder.JSONDecodeError as err:\n",
    "        data_sub = str(err)\n",
    "        sub_json_status = str(err)\n",
    "    \n",
    "    # JSON requests - moderator info\n",
    "    dict_mod = {}\n",
    "    request_url_mod = 'https://www.reddit.com/r/'+sub+'/about/moderators.json'     \n",
    "    r_mod = requests.get(request_url_mod, headers = s.headers)\n",
    "\n",
    "    try:\n",
    "        data_mod = r_mod.json()\n",
    "        mod_json_status = \"OK\"\n",
    "    except json.decoder.JSONDecodeError as err:\n",
    "        data_mod = str(err)\n",
    "        mod_json_status = str(err)    \n",
    "\n",
    "    # JSON requests - rules info\n",
    "    dict_rules = {}\n",
    "    request_url_rules = 'https://www.reddit.com/r/'+sub+'/about/rules.json'     \n",
    "    r_rules = requests.get(request_url_rules, headers = s.headers)\n",
    "\n",
    "    try:\n",
    "        data_rules = r_rules.json()\n",
    "        rules_json_status = \"OK\"\n",
    "    except json.decoder.JSONDecodeError as err:\n",
    "        data_rules = str(err)\n",
    "        rules_json_status = str(err)\n",
    "        \n",
    "    timestamp = datetime.datetime.utcfromtimestamp(time.time()).strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "                \n",
    "    # Write to dictionary for subreddit table\n",
    "    dict_sub['subreddit'] = [sub]\n",
    "    dict_sub['sub_status'] = [r_sub.status_code]\n",
    "    dict_sub['sub_reason'] = [r_sub.reason]\n",
    "    dict_sub['sub_timestamp'] = [timestamp]\n",
    "    dict_sub['sub_json_status'] = [sub_json_status]\n",
    "    dict_sub['sub_json'] = [json.dumps(data_sub)]\n",
    "    \n",
    "    # Write to dictionary for mod table\n",
    "    dict_mod['subreddit'] = [sub]\n",
    "    dict_mod['mod_status'] = [r_mod.status_code]\n",
    "    dict_mod['mod_reason'] = [r_mod.reason]\n",
    "    dict_mod['mod_timestamp'] = [timestamp]\n",
    "    dict_mod['mod_json_status'] = [mod_json_status]\n",
    "    dict_mod['mod_json'] = [json.dumps(data_mod)]\n",
    "    \n",
    "    # Write to dictionary for rules table\n",
    "    dict_rules['subreddit'] = [sub]\n",
    "    dict_rules['rules_status'] = [r_rules.status_code]\n",
    "    dict_rules['rules_reason'] = [r_rules.reason]\n",
    "    dict_rules['rules_timestamp'] = [timestamp]\n",
    "    dict_rules['rules_json_status'] = [rules_json_status]\n",
    "    dict_rules['rules_json'] = [json.dumps(data_rules)]\n",
    "               \n",
    "    pd_sub = pd.DataFrame(dict_sub)\n",
    "    pd_sub.to_sql('sub_json', if_exists='append',con = conn, index=False)\n",
    "    \n",
    "    pd_mod = pd.DataFrame(dict_mod)\n",
    "    pd_mod.to_sql('mod_json', if_exists='append',con = conn, index=False)\n",
    "    \n",
    "    pd_rules = pd.DataFrame(dict_rules)\n",
    "    pd_rules.to_sql('rules_json', if_exists='append',con = conn, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### General subreddit information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the `sub_json table`, we can use the `json_normalize` pandas command to transform the `sub_json` column into a new, fully populated data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subreddit</th>\n",
       "      <th>sub_status</th>\n",
       "      <th>sub_reason</th>\n",
       "      <th>sub_timestamp</th>\n",
       "      <th>sub_json_status</th>\n",
       "      <th>sub_json</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>seattlewa</td>\n",
       "      <td>200</td>\n",
       "      <td>OK</td>\n",
       "      <td>2020-11-02 18:15:14</td>\n",
       "      <td>OK</td>\n",
       "      <td>{\"kind\": \"t5\", \"data\": {\"user_flair_background...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>nyc</td>\n",
       "      <td>200</td>\n",
       "      <td>OK</td>\n",
       "      <td>2020-11-02 18:15:15</td>\n",
       "      <td>OK</td>\n",
       "      <td>{\"kind\": \"t5\", \"data\": {\"user_flair_background...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>chicago</td>\n",
       "      <td>200</td>\n",
       "      <td>OK</td>\n",
       "      <td>2020-11-02 18:15:16</td>\n",
       "      <td>OK</td>\n",
       "      <td>{\"kind\": \"t5\", \"data\": {\"user_flair_background...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>losangeles</td>\n",
       "      <td>200</td>\n",
       "      <td>OK</td>\n",
       "      <td>2020-11-02 18:15:17</td>\n",
       "      <td>OK</td>\n",
       "      <td>{\"kind\": \"t5\", \"data\": {\"user_flair_background...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>atlanta</td>\n",
       "      <td>200</td>\n",
       "      <td>OK</td>\n",
       "      <td>2020-11-02 18:15:17</td>\n",
       "      <td>OK</td>\n",
       "      <td>{\"kind\": \"t5\", \"data\": {\"user_flair_background...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    subreddit  sub_status sub_reason        sub_timestamp sub_json_status  \\\n",
       "0   seattlewa         200         OK  2020-11-02 18:15:14              OK   \n",
       "1         nyc         200         OK  2020-11-02 18:15:15              OK   \n",
       "2     chicago         200         OK  2020-11-02 18:15:16              OK   \n",
       "3  losangeles         200         OK  2020-11-02 18:15:17              OK   \n",
       "4     atlanta         200         OK  2020-11-02 18:15:17              OK   \n",
       "\n",
       "                                            sub_json  \n",
       "0  {\"kind\": \"t5\", \"data\": {\"user_flair_background...  \n",
       "1  {\"kind\": \"t5\", \"data\": {\"user_flair_background...  \n",
       "2  {\"kind\": \"t5\", \"data\": {\"user_flair_background...  \n",
       "3  {\"kind\": \"t5\", \"data\": {\"user_flair_background...  \n",
       "4  {\"kind\": \"t5\", \"data\": {\"user_flair_background...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Subreddit's general information\n",
    "df_sub = pd.read_sql_query(\"select * from sub_json;\", conn)\n",
    "df_sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subreddit</th>\n",
       "      <th>kind</th>\n",
       "      <th>user_flair_background_color</th>\n",
       "      <th>submit_text_html</th>\n",
       "      <th>restrict_posting</th>\n",
       "      <th>user_is_banned</th>\n",
       "      <th>free_form_reports</th>\n",
       "      <th>wiki_enabled</th>\n",
       "      <th>user_is_muted</th>\n",
       "      <th>user_can_flair_in_sr</th>\n",
       "      <th>...</th>\n",
       "      <th>restrict_commenting</th>\n",
       "      <th>user_flair_css_class</th>\n",
       "      <th>llow_images</th>\n",
       "      <th>lang</th>\n",
       "      <th>whitelist_status</th>\n",
       "      <th>url</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>banner_size</th>\n",
       "      <th>mobile_banner_image</th>\n",
       "      <th>user_is_contributor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>seattlewa</td>\n",
       "      <td>t5</td>\n",
       "      <td>None</td>\n",
       "      <td>&amp;lt;!-- SC_OFF --&amp;gt;&amp;lt;div class=\"md\"&amp;gt;&amp;lt...</td>\n",
       "      <td>True</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>en</td>\n",
       "      <td>all_ads</td>\n",
       "      <td>/r/SeattleWA/</td>\n",
       "      <td>2012-10-17 12:37:09</td>\n",
       "      <td>[653, 196]</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>nyc</td>\n",
       "      <td>t5</td>\n",
       "      <td>None</td>\n",
       "      <td>&amp;lt;!-- SC_OFF --&amp;gt;&amp;lt;div class=\"md\"&amp;gt;&amp;lt...</td>\n",
       "      <td>True</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>en</td>\n",
       "      <td>all_ads</td>\n",
       "      <td>/r/nyc/</td>\n",
       "      <td>2008-04-17 16:45:27</td>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>chicago</td>\n",
       "      <td>t5</td>\n",
       "      <td>None</td>\n",
       "      <td>&amp;lt;!-- SC_OFF --&amp;gt;&amp;lt;div class=\"md\"&amp;gt;&amp;lt...</td>\n",
       "      <td>True</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>en</td>\n",
       "      <td>all_ads</td>\n",
       "      <td>/r/chicago/</td>\n",
       "      <td>2008-01-24 22:22:33</td>\n",
       "      <td>[1280, 384]</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>losangeles</td>\n",
       "      <td>t5</td>\n",
       "      <td>None</td>\n",
       "      <td>&amp;lt;!-- SC_OFF --&amp;gt;&amp;lt;div class=\"md\"&amp;gt;&amp;lt...</td>\n",
       "      <td>True</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>en</td>\n",
       "      <td>all_ads</td>\n",
       "      <td>/r/LosAngeles/</td>\n",
       "      <td>2008-04-14 03:06:50</td>\n",
       "      <td>None</td>\n",
       "      <td>https://styles.redditmedia.com/t5_2qht0/styles...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>atlanta</td>\n",
       "      <td>t5</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>en</td>\n",
       "      <td>all_ads</td>\n",
       "      <td>/r/Atlanta/</td>\n",
       "      <td>2008-06-11 11:53:55</td>\n",
       "      <td>[1280, 384]</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 94 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    subreddit kind user_flair_background_color  \\\n",
       "0   seattlewa   t5                        None   \n",
       "1         nyc   t5                        None   \n",
       "2     chicago   t5                        None   \n",
       "3  losangeles   t5                        None   \n",
       "4     atlanta   t5                        None   \n",
       "\n",
       "                                    submit_text_html  restrict_posting  \\\n",
       "0  &lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt...              True   \n",
       "1  &lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt...              True   \n",
       "2  &lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt...              True   \n",
       "3  &lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt...              True   \n",
       "4                                               None              True   \n",
       "\n",
       "  user_is_banned  free_form_reports  wiki_enabled user_is_muted  \\\n",
       "0           None               True          True          None   \n",
       "1           None               True          True          None   \n",
       "2           None              False          True          None   \n",
       "3           None               True          True          None   \n",
       "4           None               True          True          None   \n",
       "\n",
       "  user_can_flair_in_sr  ... restrict_commenting user_flair_css_class  \\\n",
       "0                 None  ...               False                 None   \n",
       "1                 None  ...               False                 None   \n",
       "2                 None  ...               False                 None   \n",
       "3                 None  ...               False                 None   \n",
       "4                 None  ...               False                 None   \n",
       "\n",
       "  llow_images  lang whitelist_status             url         created_utc  \\\n",
       "0        True    en          all_ads   /r/SeattleWA/ 2012-10-17 12:37:09   \n",
       "1        True    en          all_ads         /r/nyc/ 2008-04-17 16:45:27   \n",
       "2        True    en          all_ads     /r/chicago/ 2008-01-24 22:22:33   \n",
       "3        True    en          all_ads  /r/LosAngeles/ 2008-04-14 03:06:50   \n",
       "4        True    en          all_ads     /r/Atlanta/ 2008-06-11 11:53:55   \n",
       "\n",
       "   banner_size                                mobile_banner_image  \\\n",
       "0   [653, 196]                                                      \n",
       "1         None                                                      \n",
       "2  [1280, 384]                                                      \n",
       "3         None  https://styles.redditmedia.com/t5_2qht0/styles...   \n",
       "4  [1280, 384]                                                      \n",
       "\n",
       "   user_is_contributor  \n",
       "0                 None  \n",
       "1                 None  \n",
       "2                 None  \n",
       "3                 None  \n",
       "4                 None  \n",
       "\n",
       "[5 rows x 94 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pandas.io.json import json_normalize\n",
    "\n",
    "# First, load the json:\n",
    "df_sub['sub_json'] = df_sub['sub_json'].apply(json.loads)\n",
    "\n",
    "# Add a subreddit name key to the JSON dictionary\n",
    "for i in df_sub.index.tolist():\n",
    "        df_sub.sub_json[i]['data']['subreddit'] = df_sub.subreddit[i]\n",
    "\n",
    "final_subdf = json_normalize(df_sub.sub_json)\n",
    "final_subdf.columns = final_subdf.columns.str.lstrip('data.') # remove the 'data.' prefix\n",
    "\n",
    "# Reorder columns\n",
    "cols = final_subdf.columns.tolist()\n",
    "cols = cols[-1:] + cols[:-1]\n",
    "final_subdf = final_subdf[cols]\n",
    "final_subdf = final_subdf.reset_index(drop=True)\n",
    "# Transform created_utc column to datetime\n",
    "final_subdf['created_utc'] = final_subdf['created_utc'].apply(datetime.datetime.fromtimestamp)\n",
    "final_subdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Note: 94 columns is not ideal---there are many columns that have mostly useless information or are just copies of other columns but in html format. When I normalize the subreddit/about.json full data set, I only pull out the `description_html`, `subscribers`, `created`, and `display_name` of each subreddit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Moderator information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The actual moderator information here is nested deeper within the JSON object, so we will need to do some preliminary work before we can use the `json_normalize` command here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subreddit</th>\n",
       "      <th>mod_status</th>\n",
       "      <th>mod_reason</th>\n",
       "      <th>mod_timestamp</th>\n",
       "      <th>mod_json_status</th>\n",
       "      <th>mod_json</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>seattlewa</td>\n",
       "      <td>200</td>\n",
       "      <td>OK</td>\n",
       "      <td>2020-11-02 18:15:14</td>\n",
       "      <td>OK</td>\n",
       "      <td>{'kind': 'UserList', 'data': {'children': [{'n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>nyc</td>\n",
       "      <td>200</td>\n",
       "      <td>OK</td>\n",
       "      <td>2020-11-02 18:15:15</td>\n",
       "      <td>OK</td>\n",
       "      <td>{'kind': 'UserList', 'data': {'children': [{'n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>chicago</td>\n",
       "      <td>200</td>\n",
       "      <td>OK</td>\n",
       "      <td>2020-11-02 18:15:16</td>\n",
       "      <td>OK</td>\n",
       "      <td>{'kind': 'UserList', 'data': {'children': [{'n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>losangeles</td>\n",
       "      <td>200</td>\n",
       "      <td>OK</td>\n",
       "      <td>2020-11-02 18:15:17</td>\n",
       "      <td>OK</td>\n",
       "      <td>{'kind': 'UserList', 'data': {'children': [{'n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>atlanta</td>\n",
       "      <td>200</td>\n",
       "      <td>OK</td>\n",
       "      <td>2020-11-02 18:15:17</td>\n",
       "      <td>OK</td>\n",
       "      <td>{'kind': 'UserList', 'data': {'children': [{'n...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    subreddit  mod_status mod_reason        mod_timestamp mod_json_status  \\\n",
       "0   seattlewa         200         OK  2020-11-02 18:15:14              OK   \n",
       "1         nyc         200         OK  2020-11-02 18:15:15              OK   \n",
       "2     chicago         200         OK  2020-11-02 18:15:16              OK   \n",
       "3  losangeles         200         OK  2020-11-02 18:15:17              OK   \n",
       "4     atlanta         200         OK  2020-11-02 18:15:17              OK   \n",
       "\n",
       "                                            mod_json  \n",
       "0  {'kind': 'UserList', 'data': {'children': [{'n...  \n",
       "1  {'kind': 'UserList', 'data': {'children': [{'n...  \n",
       "2  {'kind': 'UserList', 'data': {'children': [{'n...  \n",
       "3  {'kind': 'UserList', 'data': {'children': [{'n...  \n",
       "4  {'kind': 'UserList', 'data': {'children': [{'n...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Subreddit's general information\n",
    "df_mod = pd.read_sql_query(\"select * from mod_json;\", conn)\n",
    "df_mod['mod_json'] = df_mod['mod_json'].apply(json.loads) # load json\n",
    "df_mod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subreddit</th>\n",
       "      <th>name</th>\n",
       "      <th>author_flair_text</th>\n",
       "      <th>mod_permissions</th>\n",
       "      <th>date</th>\n",
       "      <th>rel_id</th>\n",
       "      <th>id</th>\n",
       "      <th>author_flair_css_class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>seattlewa</td>\n",
       "      <td>rattus</td>\n",
       "      <td>:snoo_tableflip: :table_flip:</td>\n",
       "      <td>[all]</td>\n",
       "      <td>2015-01-15 12:43:18</td>\n",
       "      <td>rb_8sfnq6</td>\n",
       "      <td>t2_vahn</td>\n",
       "      <td>plain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>seattlewa</td>\n",
       "      <td>isiramteal</td>\n",
       "      <td>anti-Taco timers OUT 😡👉🚪</td>\n",
       "      <td>[all]</td>\n",
       "      <td>2015-03-04 23:42:26</td>\n",
       "      <td>rb_9h4tc9</td>\n",
       "      <td>t2_lpoh8</td>\n",
       "      <td>plain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>seattlewa</td>\n",
       "      <td>ExtraNoise</td>\n",
       "      <td>None</td>\n",
       "      <td>[wiki, posts, mail, flair]</td>\n",
       "      <td>2016-06-08 21:20:04</td>\n",
       "      <td>rb_g9vt44</td>\n",
       "      <td>t2_4bg92</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>seattlewa</td>\n",
       "      <td>YopparaiNeko</td>\n",
       "      <td>Greenlake</td>\n",
       "      <td>[all]</td>\n",
       "      <td>2016-07-16 13:34:33</td>\n",
       "      <td>rb_h3cqe0</td>\n",
       "      <td>t2_gheks</td>\n",
       "      <td>plain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>seattlewa</td>\n",
       "      <td>AutoModerator</td>\n",
       "      <td>None</td>\n",
       "      <td>[all]</td>\n",
       "      <td>2016-09-06 15:44:06</td>\n",
       "      <td>rb_ibk175</td>\n",
       "      <td>t2_6l4z3</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>57</td>\n",
       "      <td>atlanta</td>\n",
       "      <td>cosby</td>\n",
       "      <td>McDonough</td>\n",
       "      <td>[all]</td>\n",
       "      <td>2013-01-31 19:40:08</td>\n",
       "      <td>rb_2k0c87</td>\n",
       "      <td>t2_3hftj</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>58</td>\n",
       "      <td>atlanta</td>\n",
       "      <td>AutoModerator</td>\n",
       "      <td>ITP</td>\n",
       "      <td>[wiki, posts, flair]</td>\n",
       "      <td>2013-05-29 05:59:17</td>\n",
       "      <td>rb_38z9su</td>\n",
       "      <td>t2_6l4z3</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>59</td>\n",
       "      <td>atlanta</td>\n",
       "      <td>oakgrove</td>\n",
       "      <td></td>\n",
       "      <td>[all]</td>\n",
       "      <td>2016-03-07 16:01:45</td>\n",
       "      <td>rb_ekfobc</td>\n",
       "      <td>t2_67qn4</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>atlanta</td>\n",
       "      <td>askatlmod</td>\n",
       "      <td></td>\n",
       "      <td>[wiki, posts, mail, flair]</td>\n",
       "      <td>2018-10-18 15:56:12</td>\n",
       "      <td>rb_11khvgc</td>\n",
       "      <td>t2_1npuwp6p</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>61</td>\n",
       "      <td>atlanta</td>\n",
       "      <td>mb44</td>\n",
       "      <td>LOLVista Hills</td>\n",
       "      <td>[all]</td>\n",
       "      <td>2019-10-25 11:16:09</td>\n",
       "      <td>rb_1kcpfdn</td>\n",
       "      <td>t2_4b396</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>62 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    subreddit           name              author_flair_text  \\\n",
       "0   seattlewa         rattus  :snoo_tableflip: :table_flip:   \n",
       "1   seattlewa     isiramteal       anti-Taco timers OUT 😡👉🚪   \n",
       "2   seattlewa     ExtraNoise                           None   \n",
       "3   seattlewa   YopparaiNeko                      Greenlake   \n",
       "4   seattlewa  AutoModerator                           None   \n",
       "..        ...            ...                            ...   \n",
       "57    atlanta          cosby                      McDonough   \n",
       "58    atlanta  AutoModerator                            ITP   \n",
       "59    atlanta       oakgrove                                  \n",
       "60    atlanta      askatlmod                                  \n",
       "61    atlanta           mb44                 LOLVista Hills   \n",
       "\n",
       "               mod_permissions                date      rel_id           id  \\\n",
       "0                        [all] 2015-01-15 12:43:18   rb_8sfnq6      t2_vahn   \n",
       "1                        [all] 2015-03-04 23:42:26   rb_9h4tc9     t2_lpoh8   \n",
       "2   [wiki, posts, mail, flair] 2016-06-08 21:20:04   rb_g9vt44     t2_4bg92   \n",
       "3                        [all] 2016-07-16 13:34:33   rb_h3cqe0     t2_gheks   \n",
       "4                        [all] 2016-09-06 15:44:06   rb_ibk175     t2_6l4z3   \n",
       "..                         ...                 ...         ...          ...   \n",
       "57                       [all] 2013-01-31 19:40:08   rb_2k0c87     t2_3hftj   \n",
       "58        [wiki, posts, flair] 2013-05-29 05:59:17   rb_38z9su     t2_6l4z3   \n",
       "59                       [all] 2016-03-07 16:01:45   rb_ekfobc     t2_67qn4   \n",
       "60  [wiki, posts, mail, flair] 2018-10-18 15:56:12  rb_11khvgc  t2_1npuwp6p   \n",
       "61                       [all] 2019-10-25 11:16:09  rb_1kcpfdn     t2_4b396   \n",
       "\n",
       "   author_flair_css_class  \n",
       "0                   plain  \n",
       "1                   plain  \n",
       "2                    None  \n",
       "3                   plain  \n",
       "4                    None  \n",
       "..                    ...  \n",
       "57                   None  \n",
       "58                   None  \n",
       "59                         \n",
       "60                   None  \n",
       "61                         \n",
       "\n",
       "[62 rows x 8 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add the subreddit name to the dictionary so we can use it as a key with the other data sets\n",
    "for i in df_mod.index.tolist():\n",
    "    children_len = len(df_mod.mod_json[i]['data']['children'])\n",
    "    children_range = list(range(0, children_len))\n",
    "    for n in children_range:\n",
    "        df_mod.mod_json[i]['data']['children'][n]['subreddit'] = df_mod.subreddit[i]\n",
    "\n",
    "mod_data = df_mod.mod_json.to_list()\n",
    "df_mod = pd.DataFrame(columns=list(mod_data[0]['data']['children'][0].keys()))\n",
    "mod_children_range = list(range(0, len(mod_data)))\n",
    "\n",
    "# Normalize the JSON and append to df_mod\n",
    "for i in mod_children_range:\n",
    "    df_mod = df_mod.append(json_normalize(mod_data[i]['data']['children']))\n",
    "    \n",
    "# Reorder columns and fix column names                      \n",
    "cols = df_mod.columns.tolist()\n",
    "cols = cols[-1:] + cols[:-1]\n",
    "df_mod = df_mod[cols]\n",
    "df_mod = df_mod.reset_index(drop=True)\n",
    "# Transform created_utc column to datetime\n",
    "df_mod['date'] = df_mod['date'].apply(datetime.datetime.fromtimestamp)\n",
    "df_mod"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rules information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll do similar work that we did on the moderator table with the rules table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subreddit</th>\n",
       "      <th>rules_status</th>\n",
       "      <th>rules_reason</th>\n",
       "      <th>rules_timestamp</th>\n",
       "      <th>rules_json_status</th>\n",
       "      <th>rules_json</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>seattlewa</td>\n",
       "      <td>200</td>\n",
       "      <td>OK</td>\n",
       "      <td>2020-11-02 18:15:14</td>\n",
       "      <td>OK</td>\n",
       "      <td>{'rules': [{'kind': 'link', 'description': 'Su...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>nyc</td>\n",
       "      <td>200</td>\n",
       "      <td>OK</td>\n",
       "      <td>2020-11-02 18:15:15</td>\n",
       "      <td>OK</td>\n",
       "      <td>{'rules': [{'kind': 'all', 'description': '', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>chicago</td>\n",
       "      <td>200</td>\n",
       "      <td>OK</td>\n",
       "      <td>2020-11-02 18:15:16</td>\n",
       "      <td>OK</td>\n",
       "      <td>{'rules': [{'kind': 'link', 'description': 'Pl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>losangeles</td>\n",
       "      <td>200</td>\n",
       "      <td>OK</td>\n",
       "      <td>2020-11-02 18:15:17</td>\n",
       "      <td>OK</td>\n",
       "      <td>{'rules': [{'kind': 'link', 'description': 'Re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>atlanta</td>\n",
       "      <td>200</td>\n",
       "      <td>OK</td>\n",
       "      <td>2020-11-02 18:15:17</td>\n",
       "      <td>OK</td>\n",
       "      <td>{'rules': [{'kind': 'all', 'description': 'No ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    subreddit  rules_status rules_reason      rules_timestamp  \\\n",
       "0   seattlewa           200           OK  2020-11-02 18:15:14   \n",
       "1         nyc           200           OK  2020-11-02 18:15:15   \n",
       "2     chicago           200           OK  2020-11-02 18:15:16   \n",
       "3  losangeles           200           OK  2020-11-02 18:15:17   \n",
       "4     atlanta           200           OK  2020-11-02 18:15:17   \n",
       "\n",
       "  rules_json_status                                         rules_json  \n",
       "0                OK  {'rules': [{'kind': 'link', 'description': 'Su...  \n",
       "1                OK  {'rules': [{'kind': 'all', 'description': '', ...  \n",
       "2                OK  {'rules': [{'kind': 'link', 'description': 'Pl...  \n",
       "3                OK  {'rules': [{'kind': 'link', 'description': 'Re...  \n",
       "4                OK  {'rules': [{'kind': 'all', 'description': 'No ...  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Subreddit's general information\n",
    "df_rules = pd.read_sql_query(\"select * from rules_json;\", conn)\n",
    "df_rules['rules_json'] = df_rules['rules_json'].apply(json.loads) # load json\n",
    "df_rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subreddit</th>\n",
       "      <th>kind</th>\n",
       "      <th>description</th>\n",
       "      <th>short_name</th>\n",
       "      <th>violation_reason</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>priority</th>\n",
       "      <th>description_html</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>seattlewa</td>\n",
       "      <td>link</td>\n",
       "      <td>Submissions should be on topic to Seattle and ...</td>\n",
       "      <td>Only Seattle and Puget Sound Related Submissions</td>\n",
       "      <td>No explicit impact or connection to Seattle.</td>\n",
       "      <td>2017-03-07 17:33:46</td>\n",
       "      <td>0</td>\n",
       "      <td>&amp;lt;!-- SC_OFF --&amp;gt;&amp;lt;div class=\"md\"&amp;gt;&amp;lt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>seattlewa</td>\n",
       "      <td>all</td>\n",
       "      <td>This discussion board promotes civil discourse...</td>\n",
       "      <td>No Personal Attacks</td>\n",
       "      <td>No Personal Attacks</td>\n",
       "      <td>2017-03-07 17:34:17</td>\n",
       "      <td>1</td>\n",
       "      <td>&amp;lt;!-- SC_OFF --&amp;gt;&amp;lt;div class=\"md\"&amp;gt;&amp;lt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>seattlewa</td>\n",
       "      <td>all</td>\n",
       "      <td>If a user is seen to regularly act in bad fai...</td>\n",
       "      <td>Challenges</td>\n",
       "      <td>Challenges</td>\n",
       "      <td>2018-05-02 12:14:19</td>\n",
       "      <td>2</td>\n",
       "      <td>&amp;lt;!-- SC_OFF --&amp;gt;&amp;lt;div class=\"md\"&amp;gt;&amp;lt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>seattlewa</td>\n",
       "      <td>all</td>\n",
       "      <td>Moderators must enforce Reddit’s site-wide rul...</td>\n",
       "      <td>Follow Reddit’s Content Policy</td>\n",
       "      <td>Breaking Reddit's Content Policy</td>\n",
       "      <td>2018-05-02 12:15:03</td>\n",
       "      <td>3</td>\n",
       "      <td>&amp;lt;!-- SC_OFF --&amp;gt;&amp;lt;div class=\"md\"&amp;gt;&amp;lt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>seattlewa</td>\n",
       "      <td>link</td>\n",
       "      <td>Reddit is supposed to catch duplicate posts, b...</td>\n",
       "      <td>Duplicate Post Source</td>\n",
       "      <td>100% Duplicate Post Source</td>\n",
       "      <td>2019-02-19 09:46:25</td>\n",
       "      <td>4</td>\n",
       "      <td>&amp;lt;!-- SC_OFF --&amp;gt;&amp;lt;div class=\"md\"&amp;gt;&amp;lt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>nyc</td>\n",
       "      <td>all</td>\n",
       "      <td></td>\n",
       "      <td>Be nice, or don't comment. Rudeness, meanness,...</td>\n",
       "      <td>Not nice, rude, mean, or otherwise unwelcoming...</td>\n",
       "      <td>2016-01-28 02:50:17</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>nyc</td>\n",
       "      <td>link</td>\n",
       "      <td>**Photos** of WTC1, sunsets, and other common ...</td>\n",
       "      <td>Questions go to /r/AskNYC. Pictures go into /r...</td>\n",
       "      <td>Miscategorized.</td>\n",
       "      <td>2016-01-28 02:51:37</td>\n",
       "      <td>1</td>\n",
       "      <td>&amp;lt;!-- SC_OFF --&amp;gt;&amp;lt;div class=\"md\"&amp;gt;&amp;lt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>nyc</td>\n",
       "      <td>all</td>\n",
       "      <td>Please do not post “shortened” links, redirect...</td>\n",
       "      <td>No link shorteners or redirects.</td>\n",
       "      <td>No link shorteners or redirects.</td>\n",
       "      <td>2016-01-28 02:52:58</td>\n",
       "      <td>2</td>\n",
       "      <td>&amp;lt;!-- SC_OFF --&amp;gt;&amp;lt;div class=\"md\"&amp;gt;&amp;lt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>nyc</td>\n",
       "      <td>link</td>\n",
       "      <td>Spamblogs, pages heavy with ads, and anything ...</td>\n",
       "      <td>No spamblogs and no ad-heavy pages</td>\n",
       "      <td>No spamblogs and no ad-heavy pages</td>\n",
       "      <td>2016-01-28 02:55:17</td>\n",
       "      <td>3</td>\n",
       "      <td>&amp;lt;!-- SC_OFF --&amp;gt;&amp;lt;div class=\"md\"&amp;gt;&amp;lt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>nyc</td>\n",
       "      <td>comment</td>\n",
       "      <td></td>\n",
       "      <td>Don't shit up comment threads</td>\n",
       "      <td>Unnecessary shit in comments</td>\n",
       "      <td>2016-01-28 08:06:43</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>nyc</td>\n",
       "      <td>all</td>\n",
       "      <td></td>\n",
       "      <td>No pictures taken without subject's permission</td>\n",
       "      <td>Picture taken without subject's permission</td>\n",
       "      <td>2016-12-17 02:58:04</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>nyc</td>\n",
       "      <td>link</td>\n",
       "      <td>Please report any submissions that are broken ...</td>\n",
       "      <td>Inaccessible website / doesn't work</td>\n",
       "      <td>This doesn't work on my device or is inaccessi...</td>\n",
       "      <td>2017-04-23 21:04:22</td>\n",
       "      <td>6</td>\n",
       "      <td>&amp;lt;!-- SC_OFF --&amp;gt;&amp;lt;div class=\"md\"&amp;gt;&amp;lt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>nyc</td>\n",
       "      <td>comment</td>\n",
       "      <td></td>\n",
       "      <td>Racism, gay bashing or antisemitism</td>\n",
       "      <td>Racist, gay bashing or antisemitic remarks</td>\n",
       "      <td>2017-05-12 15:17:22</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>nyc</td>\n",
       "      <td>link</td>\n",
       "      <td>The post is not really about NYC.</td>\n",
       "      <td>Not about NYC</td>\n",
       "      <td>Not about NYC</td>\n",
       "      <td>2017-07-26 01:23:51</td>\n",
       "      <td>8</td>\n",
       "      <td>&amp;lt;!-- SC_OFF --&amp;gt;&amp;lt;div class=\"md\"&amp;gt;&amp;lt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>chicago</td>\n",
       "      <td>link</td>\n",
       "      <td>Please keep posts relevant to the people, plac...</td>\n",
       "      <td>Rule 1: Keep it Relevant to Chicago</td>\n",
       "      <td>Relevance to Chicago</td>\n",
       "      <td>2016-01-29 15:12:04</td>\n",
       "      <td>0</td>\n",
       "      <td>&amp;lt;!-- SC_OFF --&amp;gt;&amp;lt;div class=\"md\"&amp;gt;&amp;lt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>chicago</td>\n",
       "      <td>all</td>\n",
       "      <td>Personal attacks, slap fighting, and public sh...</td>\n",
       "      <td>Rule 2: Keep it Civil</td>\n",
       "      <td>No personal attacks, public shaming, or slapfi...</td>\n",
       "      <td>2016-01-29 15:24:03</td>\n",
       "      <td>1</td>\n",
       "      <td>&amp;lt;!-- SC_OFF --&amp;gt;&amp;lt;div class=\"md\"&amp;gt;&amp;lt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>chicago</td>\n",
       "      <td>link</td>\n",
       "      <td>Photo, video, gif &amp;amp; image posts are not al...</td>\n",
       "      <td>Rule 3: Photos &amp;amp; videos are only allowed F...</td>\n",
       "      <td>Photo/video</td>\n",
       "      <td>2016-01-29 15:31:37</td>\n",
       "      <td>2</td>\n",
       "      <td>&amp;lt;!-- SC_OFF --&amp;gt;&amp;lt;div class=\"md\"&amp;gt;&amp;lt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>chicago</td>\n",
       "      <td>all</td>\n",
       "      <td>There is zero tolerance for racial slurs, bait...</td>\n",
       "      <td>Rule 4: No Racism, Bigotry or Baiting</td>\n",
       "      <td>racism, bigotry, or baiting</td>\n",
       "      <td>2016-01-29 15:42:16</td>\n",
       "      <td>3</td>\n",
       "      <td>&amp;lt;!-- SC_OFF --&amp;gt;&amp;lt;div class=\"md\"&amp;gt;&amp;lt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>chicago</td>\n",
       "      <td>link</td>\n",
       "      <td>News article posts must use the actual headlin...</td>\n",
       "      <td>Rule 5: No Editorialized or Sensationalized Ne...</td>\n",
       "      <td>Sensationalized news title</td>\n",
       "      <td>2016-01-29 15:48:14</td>\n",
       "      <td>4</td>\n",
       "      <td>&amp;lt;!-- SC_OFF --&amp;gt;&amp;lt;div class=\"md\"&amp;gt;&amp;lt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>chicago</td>\n",
       "      <td>link</td>\n",
       "      <td>In an effort to foster an engaged community,  ...</td>\n",
       "      <td>Rule 6: No Low-Effort Posts</td>\n",
       "      <td>low effort</td>\n",
       "      <td>2016-01-29 17:28:43</td>\n",
       "      <td>5</td>\n",
       "      <td>&amp;lt;!-- SC_OFF --&amp;gt;&amp;lt;div class=\"md\"&amp;gt;&amp;lt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>chicago</td>\n",
       "      <td>all</td>\n",
       "      <td>Duplicate stories and/or posts about the same ...</td>\n",
       "      <td>Rule 7: No Duplicate Posts or Pasted Articles</td>\n",
       "      <td>duplicate post or pasted article</td>\n",
       "      <td>2019-08-28 19:28:13</td>\n",
       "      <td>6</td>\n",
       "      <td>&amp;lt;!-- SC_OFF --&amp;gt;&amp;lt;div class=\"md\"&amp;gt;&amp;lt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>chicago</td>\n",
       "      <td>all</td>\n",
       "      <td>Buying, selling, auctioning, giveaways, promo/...</td>\n",
       "      <td>Rule 8: No Buying, Selling, Promoting, or Crow...</td>\n",
       "      <td>buying, selling, promoting, or crowdfunding</td>\n",
       "      <td>2019-08-28 19:32:57</td>\n",
       "      <td>7</td>\n",
       "      <td>&amp;lt;!-- SC_OFF --&amp;gt;&amp;lt;div class=\"md\"&amp;gt;&amp;lt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>chicago</td>\n",
       "      <td>all</td>\n",
       "      <td>Posts that ask for user participation for gain...</td>\n",
       "      <td>Rule 9: No Crowdsourcing or Political Advertising</td>\n",
       "      <td>Crowdsourcing or political advertising</td>\n",
       "      <td>2019-08-28 19:34:13</td>\n",
       "      <td>8</td>\n",
       "      <td>&amp;lt;!-- SC_OFF --&amp;gt;&amp;lt;div class=\"md\"&amp;gt;&amp;lt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>losangeles</td>\n",
       "      <td>link</td>\n",
       "      <td>Requests for recommendations go to /r/AskLosAn...</td>\n",
       "      <td>Looking for recommendations?</td>\n",
       "      <td>Didn't check the map.</td>\n",
       "      <td>2019-05-05 05:48:19</td>\n",
       "      <td>0</td>\n",
       "      <td>&amp;lt;!-- SC_OFF --&amp;gt;&amp;lt;div class=\"md\"&amp;gt;&amp;lt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>losangeles</td>\n",
       "      <td>link</td>\n",
       "      <td>* Questions go to **/r/AskLosAngeles**\\n* Crai...</td>\n",
       "      <td>Check the \"Common Topics\" first.</td>\n",
       "      <td>Common Topic</td>\n",
       "      <td>2019-04-18 10:35:51</td>\n",
       "      <td>1</td>\n",
       "      <td>&amp;lt;!-- SC_OFF --&amp;gt;&amp;lt;div class=\"md\"&amp;gt;&amp;lt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>losangeles</td>\n",
       "      <td>all</td>\n",
       "      <td>Do not post personal info. This includes track...</td>\n",
       "      <td>No posting personal information.</td>\n",
       "      <td>No Personal Info</td>\n",
       "      <td>2017-03-08 17:16:45</td>\n",
       "      <td>2</td>\n",
       "      <td>&amp;lt;!-- SC_OFF --&amp;gt;&amp;lt;div class=\"md\"&amp;gt;&amp;lt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>losangeles</td>\n",
       "      <td>all</td>\n",
       "      <td>Harassing other users will not be tolerated an...</td>\n",
       "      <td>No harassing other users.</td>\n",
       "      <td>Harassment</td>\n",
       "      <td>2017-03-08 17:18:13</td>\n",
       "      <td>3</td>\n",
       "      <td>&amp;lt;!-- SC_OFF --&amp;gt;&amp;lt;div class=\"md\"&amp;gt;&amp;lt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>losangeles</td>\n",
       "      <td>all</td>\n",
       "      <td>Bigoted remarks will not be tolerated and will...</td>\n",
       "      <td>Hate speech will not be tolerated.</td>\n",
       "      <td>Bigotry/slur</td>\n",
       "      <td>2017-03-08 17:17:40</td>\n",
       "      <td>4</td>\n",
       "      <td>&amp;lt;!-- SC_OFF --&amp;gt;&amp;lt;div class=\"md\"&amp;gt;&amp;lt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>losangeles</td>\n",
       "      <td>all</td>\n",
       "      <td>Suggesting, implying, inciting unethical pract...</td>\n",
       "      <td>No unethical comments or posts.</td>\n",
       "      <td>Unethical</td>\n",
       "      <td>2018-06-29 00:53:09</td>\n",
       "      <td>5</td>\n",
       "      <td>&amp;lt;!-- SC_OFF --&amp;gt;&amp;lt;div class=\"md\"&amp;gt;&amp;lt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>losangeles</td>\n",
       "      <td>link</td>\n",
       "      <td>Do not editorialize your post title when linki...</td>\n",
       "      <td>Do not editorialize your titles.</td>\n",
       "      <td>Do not editorialize your titles.</td>\n",
       "      <td>2017-03-08 17:18:34</td>\n",
       "      <td>6</td>\n",
       "      <td>&amp;lt;!-- SC_OFF --&amp;gt;&amp;lt;div class=\"md\"&amp;gt;&amp;lt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>losangeles</td>\n",
       "      <td>link</td>\n",
       "      <td>Posts must be about Los Angeles City or Los An...</td>\n",
       "      <td>Posts must be about Los Angeles.</td>\n",
       "      <td>Not about LA</td>\n",
       "      <td>2019-02-20 10:12:31</td>\n",
       "      <td>7</td>\n",
       "      <td>&amp;lt;!-- SC_OFF --&amp;gt;&amp;lt;div class=\"md\"&amp;gt;&amp;lt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>losangeles</td>\n",
       "      <td>link</td>\n",
       "      <td>Articles or discussions that have already been...</td>\n",
       "      <td>Reposts may be removed.</td>\n",
       "      <td>Already posted.</td>\n",
       "      <td>2019-05-22 18:23:36</td>\n",
       "      <td>8</td>\n",
       "      <td>&amp;lt;!-- SC_OFF --&amp;gt;&amp;lt;div class=\"md\"&amp;gt;&amp;lt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>losangeles</td>\n",
       "      <td>link</td>\n",
       "      <td></td>\n",
       "      <td>Buying/Selling? Post in /r/LAlist.</td>\n",
       "      <td>Please post to /r/LAlist.</td>\n",
       "      <td>2019-07-17 14:31:24</td>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>losangeles</td>\n",
       "      <td>link</td>\n",
       "      <td>Shitposts must include at least one OC/user cr...</td>\n",
       "      <td>Shitposts require images</td>\n",
       "      <td>Shitposts must include at least one OC/user cr...</td>\n",
       "      <td>2019-10-29 19:59:32</td>\n",
       "      <td>10</td>\n",
       "      <td>&amp;lt;!-- SC_OFF --&amp;gt;&amp;lt;div class=\"md\"&amp;gt;&amp;lt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>atlanta</td>\n",
       "      <td>all</td>\n",
       "      <td>No racism, homophobia, or general attacks on o...</td>\n",
       "      <td>Racism/Homophobia/Name Calling/Attacks</td>\n",
       "      <td>Racism/Homophobia/Name Calling/Attacks</td>\n",
       "      <td>2016-01-26 14:13:11</td>\n",
       "      <td>0</td>\n",
       "      <td>&amp;lt;!-- SC_OFF --&amp;gt;&amp;lt;div class=\"md\"&amp;gt;&amp;lt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>atlanta</td>\n",
       "      <td>all</td>\n",
       "      <td>Spam is a hard word to define. In addition to ...</td>\n",
       "      <td>Spamming</td>\n",
       "      <td>Spamming</td>\n",
       "      <td>2016-01-26 14:18:41</td>\n",
       "      <td>1</td>\n",
       "      <td>&amp;lt;!-- SC_OFF --&amp;gt;&amp;lt;div class=\"md\"&amp;gt;&amp;lt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>atlanta</td>\n",
       "      <td>all</td>\n",
       "      <td>Missing Persons posts are only permitted when ...</td>\n",
       "      <td>Missing Persons/Pets and Lost/Stolen Property</td>\n",
       "      <td>Missing Without Source</td>\n",
       "      <td>2016-01-26 14:22:36</td>\n",
       "      <td>2</td>\n",
       "      <td>&amp;lt;!-- SC_OFF --&amp;gt;&amp;lt;div class=\"md\"&amp;gt;&amp;lt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37</td>\n",
       "      <td>atlanta</td>\n",
       "      <td>link</td>\n",
       "      <td>Before posting you should ask yourself, \"Does ...</td>\n",
       "      <td>Not Atlanta/Metro Centric</td>\n",
       "      <td>Not Atlanta/Metro Centric</td>\n",
       "      <td>2016-01-26 14:24:50</td>\n",
       "      <td>3</td>\n",
       "      <td>&amp;lt;!-- SC_OFF --&amp;gt;&amp;lt;div class=\"md\"&amp;gt;&amp;lt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38</td>\n",
       "      <td>atlanta</td>\n",
       "      <td>comment</td>\n",
       "      <td>Comments must be related to the topic at hand....</td>\n",
       "      <td>Stay On Topic</td>\n",
       "      <td>Off Topic</td>\n",
       "      <td>2020-07-12 19:20:20</td>\n",
       "      <td>4</td>\n",
       "      <td>&amp;lt;!-- SC_OFF --&amp;gt;&amp;lt;div class=\"md\"&amp;gt;&amp;lt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39</td>\n",
       "      <td>atlanta</td>\n",
       "      <td>all</td>\n",
       "      <td>Trolls make a deliberately offensive or provoc...</td>\n",
       "      <td>No Trolling</td>\n",
       "      <td>No Trolling</td>\n",
       "      <td>2018-02-07 14:33:43</td>\n",
       "      <td>5</td>\n",
       "      <td>&amp;lt;!-- SC_OFF --&amp;gt;&amp;lt;div class=\"md\"&amp;gt;&amp;lt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>atlanta</td>\n",
       "      <td>link</td>\n",
       "      <td>The internet doesn't need any more low quality...</td>\n",
       "      <td>No Low Quality / Memes</td>\n",
       "      <td>No Low Quality / Memes</td>\n",
       "      <td>2018-02-07 14:36:49</td>\n",
       "      <td>6</td>\n",
       "      <td>&amp;lt;!-- SC_OFF --&amp;gt;&amp;lt;div class=\"md\"&amp;gt;&amp;lt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41</td>\n",
       "      <td>atlanta</td>\n",
       "      <td>all</td>\n",
       "      <td>This is a complicated rule but easy to enforce...</td>\n",
       "      <td>No Referral Codes or Urls That Benefit OP</td>\n",
       "      <td>No Referral Codes</td>\n",
       "      <td>2018-02-07 15:01:27</td>\n",
       "      <td>7</td>\n",
       "      <td>&amp;lt;!-- SC_OFF --&amp;gt;&amp;lt;div class=\"md\"&amp;gt;&amp;lt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42</td>\n",
       "      <td>atlanta</td>\n",
       "      <td>link</td>\n",
       "      <td>You may not buy or sell anything (including bo...</td>\n",
       "      <td>No Buying, Selling, or Promotion</td>\n",
       "      <td>No Buying or Selling</td>\n",
       "      <td>2020-07-30 19:12:54</td>\n",
       "      <td>8</td>\n",
       "      <td>&amp;lt;!-- SC_OFF --&amp;gt;&amp;lt;div class=\"md\"&amp;gt;&amp;lt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43</td>\n",
       "      <td>atlanta</td>\n",
       "      <td>link</td>\n",
       "      <td>Please flair political posts with the \"Politic...</td>\n",
       "      <td>Use Politics Post Flair, Only Atlanta-Related ...</td>\n",
       "      <td>Politics</td>\n",
       "      <td>2018-10-21 19:46:54</td>\n",
       "      <td>9</td>\n",
       "      <td>&amp;lt;!-- SC_OFF --&amp;gt;&amp;lt;div class=\"md\"&amp;gt;&amp;lt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44</td>\n",
       "      <td>atlanta</td>\n",
       "      <td>link</td>\n",
       "      <td>Surveys, forms, and research studies are not a...</td>\n",
       "      <td>No Surveys/Forms/Research Studies</td>\n",
       "      <td>Survey</td>\n",
       "      <td>2019-12-09 14:54:24</td>\n",
       "      <td>10</td>\n",
       "      <td>&amp;lt;!-- SC_OFF --&amp;gt;&amp;lt;div class=\"md\"&amp;gt;&amp;lt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45</td>\n",
       "      <td>atlanta</td>\n",
       "      <td>all</td>\n",
       "      <td>All events should go to the [weekly events thr...</td>\n",
       "      <td>Events Go In The Weekly Events Thread</td>\n",
       "      <td>Event</td>\n",
       "      <td>2020-02-24 12:16:01</td>\n",
       "      <td>11</td>\n",
       "      <td>&amp;lt;!-- SC_OFF --&amp;gt;&amp;lt;div class=\"md\"&amp;gt;&amp;lt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46</td>\n",
       "      <td>atlanta</td>\n",
       "      <td>all</td>\n",
       "      <td>Crowdfunding sites are blacklisted reddit-wide...</td>\n",
       "      <td>No Crowdfunding, Donations, or other Solicitation</td>\n",
       "      <td>No Crowdfunding</td>\n",
       "      <td>2017-04-27 13:45:19</td>\n",
       "      <td>12</td>\n",
       "      <td>&amp;lt;!-- SC_OFF --&amp;gt;&amp;lt;div class=\"md\"&amp;gt;&amp;lt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>47</td>\n",
       "      <td>atlanta</td>\n",
       "      <td>link</td>\n",
       "      <td>Do not post articles that are behind a paywall...</td>\n",
       "      <td>Don't Post Articles Behind a Paywall</td>\n",
       "      <td>Behind a Paywall</td>\n",
       "      <td>2020-05-19 14:26:55</td>\n",
       "      <td>13</td>\n",
       "      <td>&amp;lt;!-- SC_OFF --&amp;gt;&amp;lt;div class=\"md\"&amp;gt;&amp;lt...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     subreddit     kind                                        description  \\\n",
       "0    seattlewa     link  Submissions should be on topic to Seattle and ...   \n",
       "1    seattlewa      all  This discussion board promotes civil discourse...   \n",
       "2    seattlewa      all   If a user is seen to regularly act in bad fai...   \n",
       "3    seattlewa      all  Moderators must enforce Reddit’s site-wide rul...   \n",
       "4    seattlewa     link  Reddit is supposed to catch duplicate posts, b...   \n",
       "5          nyc      all                                                      \n",
       "6          nyc     link  **Photos** of WTC1, sunsets, and other common ...   \n",
       "7          nyc      all  Please do not post “shortened” links, redirect...   \n",
       "8          nyc     link  Spamblogs, pages heavy with ads, and anything ...   \n",
       "9          nyc  comment                                                      \n",
       "10         nyc      all                                                      \n",
       "11         nyc     link  Please report any submissions that are broken ...   \n",
       "12         nyc  comment                                                      \n",
       "13         nyc     link                  The post is not really about NYC.   \n",
       "14     chicago     link  Please keep posts relevant to the people, plac...   \n",
       "15     chicago      all  Personal attacks, slap fighting, and public sh...   \n",
       "16     chicago     link  Photo, video, gif &amp; image posts are not al...   \n",
       "17     chicago      all  There is zero tolerance for racial slurs, bait...   \n",
       "18     chicago     link  News article posts must use the actual headlin...   \n",
       "19     chicago     link  In an effort to foster an engaged community,  ...   \n",
       "20     chicago      all  Duplicate stories and/or posts about the same ...   \n",
       "21     chicago      all  Buying, selling, auctioning, giveaways, promo/...   \n",
       "22     chicago      all  Posts that ask for user participation for gain...   \n",
       "23  losangeles     link  Requests for recommendations go to /r/AskLosAn...   \n",
       "24  losangeles     link  * Questions go to **/r/AskLosAngeles**\\n* Crai...   \n",
       "25  losangeles      all  Do not post personal info. This includes track...   \n",
       "26  losangeles      all  Harassing other users will not be tolerated an...   \n",
       "27  losangeles      all  Bigoted remarks will not be tolerated and will...   \n",
       "28  losangeles      all  Suggesting, implying, inciting unethical pract...   \n",
       "29  losangeles     link  Do not editorialize your post title when linki...   \n",
       "30  losangeles     link  Posts must be about Los Angeles City or Los An...   \n",
       "31  losangeles     link  Articles or discussions that have already been...   \n",
       "32  losangeles     link                                                      \n",
       "33  losangeles     link  Shitposts must include at least one OC/user cr...   \n",
       "34     atlanta      all  No racism, homophobia, or general attacks on o...   \n",
       "35     atlanta      all  Spam is a hard word to define. In addition to ...   \n",
       "36     atlanta      all  Missing Persons posts are only permitted when ...   \n",
       "37     atlanta     link  Before posting you should ask yourself, \"Does ...   \n",
       "38     atlanta  comment  Comments must be related to the topic at hand....   \n",
       "39     atlanta      all  Trolls make a deliberately offensive or provoc...   \n",
       "40     atlanta     link  The internet doesn't need any more low quality...   \n",
       "41     atlanta      all  This is a complicated rule but easy to enforce...   \n",
       "42     atlanta     link  You may not buy or sell anything (including bo...   \n",
       "43     atlanta     link  Please flair political posts with the \"Politic...   \n",
       "44     atlanta     link  Surveys, forms, and research studies are not a...   \n",
       "45     atlanta      all  All events should go to the [weekly events thr...   \n",
       "46     atlanta      all  Crowdfunding sites are blacklisted reddit-wide...   \n",
       "47     atlanta     link  Do not post articles that are behind a paywall...   \n",
       "\n",
       "                                           short_name  \\\n",
       "0    Only Seattle and Puget Sound Related Submissions   \n",
       "1                                 No Personal Attacks   \n",
       "2                                          Challenges   \n",
       "3                      Follow Reddit’s Content Policy   \n",
       "4                               Duplicate Post Source   \n",
       "5   Be nice, or don't comment. Rudeness, meanness,...   \n",
       "6   Questions go to /r/AskNYC. Pictures go into /r...   \n",
       "7                    No link shorteners or redirects.   \n",
       "8                  No spamblogs and no ad-heavy pages   \n",
       "9                       Don't shit up comment threads   \n",
       "10     No pictures taken without subject's permission   \n",
       "11                Inaccessible website / doesn't work   \n",
       "12                Racism, gay bashing or antisemitism   \n",
       "13                                      Not about NYC   \n",
       "14                Rule 1: Keep it Relevant to Chicago   \n",
       "15                              Rule 2: Keep it Civil   \n",
       "16  Rule 3: Photos &amp; videos are only allowed F...   \n",
       "17              Rule 4: No Racism, Bigotry or Baiting   \n",
       "18  Rule 5: No Editorialized or Sensationalized Ne...   \n",
       "19                        Rule 6: No Low-Effort Posts   \n",
       "20      Rule 7: No Duplicate Posts or Pasted Articles   \n",
       "21  Rule 8: No Buying, Selling, Promoting, or Crow...   \n",
       "22  Rule 9: No Crowdsourcing or Political Advertising   \n",
       "23                       Looking for recommendations?   \n",
       "24                   Check the \"Common Topics\" first.   \n",
       "25                   No posting personal information.   \n",
       "26                          No harassing other users.   \n",
       "27                 Hate speech will not be tolerated.   \n",
       "28                    No unethical comments or posts.   \n",
       "29                   Do not editorialize your titles.   \n",
       "30                   Posts must be about Los Angeles.   \n",
       "31                            Reposts may be removed.   \n",
       "32                 Buying/Selling? Post in /r/LAlist.   \n",
       "33                           Shitposts require images   \n",
       "34             Racism/Homophobia/Name Calling/Attacks   \n",
       "35                                           Spamming   \n",
       "36      Missing Persons/Pets and Lost/Stolen Property   \n",
       "37                          Not Atlanta/Metro Centric   \n",
       "38                                      Stay On Topic   \n",
       "39                                        No Trolling   \n",
       "40                             No Low Quality / Memes   \n",
       "41          No Referral Codes or Urls That Benefit OP   \n",
       "42                   No Buying, Selling, or Promotion   \n",
       "43  Use Politics Post Flair, Only Atlanta-Related ...   \n",
       "44                  No Surveys/Forms/Research Studies   \n",
       "45              Events Go In The Weekly Events Thread   \n",
       "46  No Crowdfunding, Donations, or other Solicitation   \n",
       "47               Don't Post Articles Behind a Paywall   \n",
       "\n",
       "                                     violation_reason         created_utc  \\\n",
       "0        No explicit impact or connection to Seattle. 2017-03-07 17:33:46   \n",
       "1                                 No Personal Attacks 2017-03-07 17:34:17   \n",
       "2                                          Challenges 2018-05-02 12:14:19   \n",
       "3                    Breaking Reddit's Content Policy 2018-05-02 12:15:03   \n",
       "4                          100% Duplicate Post Source 2019-02-19 09:46:25   \n",
       "5   Not nice, rude, mean, or otherwise unwelcoming... 2016-01-28 02:50:17   \n",
       "6                                     Miscategorized. 2016-01-28 02:51:37   \n",
       "7                    No link shorteners or redirects. 2016-01-28 02:52:58   \n",
       "8                  No spamblogs and no ad-heavy pages 2016-01-28 02:55:17   \n",
       "9                        Unnecessary shit in comments 2016-01-28 08:06:43   \n",
       "10         Picture taken without subject's permission 2016-12-17 02:58:04   \n",
       "11  This doesn't work on my device or is inaccessi... 2017-04-23 21:04:22   \n",
       "12         Racist, gay bashing or antisemitic remarks 2017-05-12 15:17:22   \n",
       "13                                      Not about NYC 2017-07-26 01:23:51   \n",
       "14                               Relevance to Chicago 2016-01-29 15:12:04   \n",
       "15  No personal attacks, public shaming, or slapfi... 2016-01-29 15:24:03   \n",
       "16                                        Photo/video 2016-01-29 15:31:37   \n",
       "17                        racism, bigotry, or baiting 2016-01-29 15:42:16   \n",
       "18                         Sensationalized news title 2016-01-29 15:48:14   \n",
       "19                                         low effort 2016-01-29 17:28:43   \n",
       "20                   duplicate post or pasted article 2019-08-28 19:28:13   \n",
       "21        buying, selling, promoting, or crowdfunding 2019-08-28 19:32:57   \n",
       "22             Crowdsourcing or political advertising 2019-08-28 19:34:13   \n",
       "23                              Didn't check the map. 2019-05-05 05:48:19   \n",
       "24                                       Common Topic 2019-04-18 10:35:51   \n",
       "25                                   No Personal Info 2017-03-08 17:16:45   \n",
       "26                                         Harassment 2017-03-08 17:18:13   \n",
       "27                                       Bigotry/slur 2017-03-08 17:17:40   \n",
       "28                                          Unethical 2018-06-29 00:53:09   \n",
       "29                   Do not editorialize your titles. 2017-03-08 17:18:34   \n",
       "30                                       Not about LA 2019-02-20 10:12:31   \n",
       "31                                    Already posted. 2019-05-22 18:23:36   \n",
       "32                          Please post to /r/LAlist. 2019-07-17 14:31:24   \n",
       "33  Shitposts must include at least one OC/user cr... 2019-10-29 19:59:32   \n",
       "34             Racism/Homophobia/Name Calling/Attacks 2016-01-26 14:13:11   \n",
       "35                                           Spamming 2016-01-26 14:18:41   \n",
       "36                             Missing Without Source 2016-01-26 14:22:36   \n",
       "37                          Not Atlanta/Metro Centric 2016-01-26 14:24:50   \n",
       "38                                          Off Topic 2020-07-12 19:20:20   \n",
       "39                                        No Trolling 2018-02-07 14:33:43   \n",
       "40                             No Low Quality / Memes 2018-02-07 14:36:49   \n",
       "41                                  No Referral Codes 2018-02-07 15:01:27   \n",
       "42                               No Buying or Selling 2020-07-30 19:12:54   \n",
       "43                                           Politics 2018-10-21 19:46:54   \n",
       "44                                             Survey 2019-12-09 14:54:24   \n",
       "45                                              Event 2020-02-24 12:16:01   \n",
       "46                                    No Crowdfunding 2017-04-27 13:45:19   \n",
       "47                                   Behind a Paywall 2020-05-19 14:26:55   \n",
       "\n",
       "    priority                                   description_html  \n",
       "0          0  &lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt...  \n",
       "1          1  &lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt...  \n",
       "2          2  &lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt...  \n",
       "3          3  &lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt...  \n",
       "4          4  &lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt...  \n",
       "5          0                                                NaN  \n",
       "6          1  &lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt...  \n",
       "7          2  &lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt...  \n",
       "8          3  &lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt...  \n",
       "9          4                                                NaN  \n",
       "10         5                                                NaN  \n",
       "11         6  &lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt...  \n",
       "12         7                                                NaN  \n",
       "13         8  &lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt...  \n",
       "14         0  &lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt...  \n",
       "15         1  &lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt...  \n",
       "16         2  &lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt...  \n",
       "17         3  &lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt...  \n",
       "18         4  &lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt...  \n",
       "19         5  &lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt...  \n",
       "20         6  &lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt...  \n",
       "21         7  &lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt...  \n",
       "22         8  &lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt...  \n",
       "23         0  &lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt...  \n",
       "24         1  &lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt...  \n",
       "25         2  &lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt...  \n",
       "26         3  &lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt...  \n",
       "27         4  &lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt...  \n",
       "28         5  &lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt...  \n",
       "29         6  &lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt...  \n",
       "30         7  &lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt...  \n",
       "31         8  &lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt...  \n",
       "32         9                                                NaN  \n",
       "33        10  &lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt...  \n",
       "34         0  &lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt...  \n",
       "35         1  &lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt...  \n",
       "36         2  &lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt...  \n",
       "37         3  &lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt...  \n",
       "38         4  &lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt...  \n",
       "39         5  &lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt...  \n",
       "40         6  &lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt...  \n",
       "41         7  &lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt...  \n",
       "42         8  &lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt...  \n",
       "43         9  &lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt...  \n",
       "44        10  &lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt...  \n",
       "45        11  &lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt...  \n",
       "46        12  &lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt...  \n",
       "47        13  &lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt...  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# First, add 'subreddit' key to the JSON dict\n",
    "for i in df_rules.index.tolist():\n",
    "    df_rules.rules_json[i]['subreddit'] = df_rules.subreddit[i]\n",
    "\n",
    "rules_data = df_rules.rules_json.tolist()\n",
    "\n",
    "# Normalize the JSON and append to df_rules\n",
    "df_rules = json_normalize(rules_data, record_path=['rules'], meta=['subreddit'])\n",
    "\n",
    "# Reorder columns and fix column names   \n",
    "cols = df_rules.columns.tolist()\n",
    "cols = cols[-1:] + cols[:-1]\n",
    "df_rules = df_rules[cols]\n",
    "df_rules.columns = df_rules.columns.str.replace(\"data.\",\"\")\n",
    "df_rules = df_rules.reset_index(drop=True)\n",
    "# Transform created_utc column to datetime\n",
    "df_rules['created_utc'] = df_rules['created_utc'].apply(datetime.datetime.fromtimestamp)\n",
    "df_rules"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
